{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9cd0eaec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All imports successful!\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import pm4py\n",
    "from pm4py.objects.log.util import dataframe_utils\n",
    "from pm4py.objects.conversion.log import converter as log_converter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set style (try different options if this fails)\n",
    "try:\n",
    "    plt.style.use('seaborn-v0_8-darkgrid')\n",
    "except:\n",
    "    plt.style.use('seaborn')\n",
    "    \n",
    "print(\"All imports successful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11eaf3b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e79d171a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total events: 6005\n",
      "Unique cases: 477\n",
      "Time range: 51.90 - 5004.21\n",
      "\n",
      "Activity distribution:\n",
      "activity\n",
      "MOULDING              510\n",
      "QC_AFTER_MOULDING     510\n",
      "ASSEMBLY_1            509\n",
      "QC_AFTER_ASSEMBLY1    509\n",
      "QC_AFTER_ASSEMBLY2    504\n",
      "ASSEMBLY_2            504\n",
      "QC_AFTER_PACKAGING    503\n",
      "PACKAGING             503\n",
      "QC_AFTER_SORTING      500\n",
      "SORTING               500\n",
      "START                 477\n",
      "END                   476\n",
      "Name: count, dtype: int64\n",
      "\n",
      "First 10 starts at ASSEMBLY_2\n",
      "     case_id   timestamp          resource\n",
      "11         1   61.116517  ASSEMBLY2_LINE_1\n",
      "25         0   69.797968  ASSEMBLY2_LINE_2\n",
      "33         2   77.668036  ASSEMBLY2_LINE_1\n",
      "35         3   81.228050  ASSEMBLY2_LINE_2\n",
      "57         4  101.265794  ASSEMBLY2_LINE_1\n",
      "59         5  101.389980  ASSEMBLY2_LINE_2\n",
      "85         7  140.492282  ASSEMBLY2_LINE_2\n",
      "89         6  146.938405  ASSEMBLY2_LINE_1\n",
      "103        8  157.136339  ASSEMBLY2_LINE_2\n",
      "121        9  174.356464  ASSEMBLY2_LINE_1\n",
      "\n",
      "Trace for case 0 at ASSEMBLY_1:\n",
      "    timestamp            activity   status          resource\n",
      "3   53.760724          ASSEMBLY_1  running  LINE_1_ASSEMBLY1\n",
      "24  69.797968  QC_AFTER_ASSEMBLY1  gateway               NaN\n",
      "\n",
      "Visual FIFO check (first 15 at ASSEMBLY_2):\n",
      "     case_id   timestamp          resource\n",
      "11         1   61.116517  ASSEMBLY2_LINE_1\n",
      "25         0   69.797968  ASSEMBLY2_LINE_2\n",
      "33         2   77.668036  ASSEMBLY2_LINE_1\n",
      "35         3   81.228050  ASSEMBLY2_LINE_2\n",
      "57         4  101.265794  ASSEMBLY2_LINE_1\n",
      "59         5  101.389980  ASSEMBLY2_LINE_2\n",
      "85         7  140.492282  ASSEMBLY2_LINE_2\n",
      "89         6  146.938405  ASSEMBLY2_LINE_1\n",
      "103        8  157.136339  ASSEMBLY2_LINE_2\n",
      "121        9  174.356464  ASSEMBLY2_LINE_1\n",
      "129       10  185.347790  ASSEMBLY2_LINE_2\n",
      "133       10  186.540822  ASSEMBLY2_LINE_1\n",
      "153       11  259.666609  ASSEMBLY2_LINE_2\n",
      "155       12  260.744534  ASSEMBLY2_LINE_1\n",
      "159       13  263.806483  ASSEMBLY2_LINE_2\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Load CSV (Windows-safe path)\n",
    "df = pd.read_csv(r'results\\FIFO_l0.1_actuator_manufacturing_with_rework.csv')\n",
    "\n",
    "print(f\"Total events: {len(df)}\")\n",
    "print(f\"Unique cases: {df['case_id'].nunique()}\")\n",
    "print(f\"Time range: {df['timestamp'].min():.2f} - {df['timestamp'].max():.2f}\")\n",
    "print(f\"\\nActivity distribution:\\n{df['activity'].value_counts()}\")\n",
    "\n",
    "# 2) Check FIFO order at a pooled station (e.g., ASSEMBLY_2)\n",
    "st = \"ASSEMBLY_2\"\n",
    "x = df[(df[\"status\"]==\"running\") & (df[\"activity\"]==st)].copy().sort_values(\"timestamp\")\n",
    "print(\"\\nFirst 10 starts at\", st)\n",
    "print(x[[\"case_id\",\"timestamp\",\"resource\"]].head(10))\n",
    "\n",
    "# 3) Check that A1 rework returns to the SAME queue/lane\n",
    "# Find an A1 label that exists in this log (pooled or lane-specific)\n",
    "a1_labels = [a for a in df[\"activity\"].unique() if re.fullmatch(r\"ASSEMBLY_1(_\\d+)?\", str(a))]\n",
    "if a1_labels:\n",
    "    lane = sorted(a1_labels)[0]  # pick the first matching label\n",
    "    qc_label = \"QC_AFTER_ASSEMBLY1\" if lane == \"ASSEMBLY_1\" else f\"QC_AFTER_{lane}\"\n",
    "    cid_example = df[(df[\"activity\"]==lane) & (df[\"status\"]==\"running\")][\"case_id\"].head(1)\n",
    "    if not cid_example.empty:\n",
    "        cid = int(cid_example.iloc[0])\n",
    "        y = df[(df[\"case_id\"]==cid) & df[\"activity\"].isin([lane, qc_label])].sort_values(\"timestamp\")\n",
    "        print(f\"\\nTrace for case {cid} at {lane}:\")\n",
    "        print(y[[\"timestamp\",\"activity\",\"status\",\"resource\"]].head(20))\n",
    "    else:\n",
    "        print(f\"\\nNo runs found for {lane} in this file.\")\n",
    "else:\n",
    "    print(\"\\nNo ASSEMBLY_1 labels found (pooled or lanes).\")\n",
    "\n",
    "# 4) Visual FIFO check at ASSEMBLY_2 (first 15 starts)\n",
    "def station_fifo_sample(station):\n",
    "    return df[(df[\"activity\"]==station) & (df[\"status\"]==\"running\")] \\\n",
    "             [[\"case_id\",\"timestamp\",\"resource\"]].sort_values(\"timestamp\").head(15)\n",
    "\n",
    "print(\"\\nVisual FIFO check (first 15 at ASSEMBLY_2):\")\n",
    "print(station_fifo_sample(\"ASSEMBLY_2\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83798eca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      station  num_starts  fifo_violations\n",
      "0  ASSEMBLY_1         509               11\n",
      "1  ASSEMBLY_2         504               12\n",
      "2    MOULDING         510                0\n",
      "3   PACKAGING         503                5\n",
      "4     SORTING         500               10\n",
      "\n",
      "Sample suspected FIFO breaches (visit-aligned):\n",
      "       station case_id  arrival_time   start_time          resource\n",
      "0   ASSEMBLY_1      33    402.311682   411.599726  LINE_3_ASSEMBLY1\n",
      "1   ASSEMBLY_1     103   1102.818885  1113.767775  LINE_1_ASSEMBLY1\n",
      "2   ASSEMBLY_1     138   1455.327242  1465.529719  LINE_3_ASSEMBLY1\n",
      "3   ASSEMBLY_1     169   1773.614091  1776.680566  LINE_3_ASSEMBLY1\n",
      "4   ASSEMBLY_1     185   1856.545798  1861.188596  LINE_3_ASSEMBLY1\n",
      "5   ASSEMBLY_2      36    438.669189   443.125091  ASSEMBLY2_LINE_2\n",
      "6   ASSEMBLY_2      52    597.094904   599.170323  ASSEMBLY2_LINE_2\n",
      "7   ASSEMBLY_2      50    603.308664   614.308147  ASSEMBLY2_LINE_1\n",
      "8   ASSEMBLY_2     103   1113.767775  1130.550345  ASSEMBLY2_LINE_1\n",
      "9   ASSEMBLY_2     136   1428.722892  1437.719516  ASSEMBLY2_LINE_2\n",
      "10   PACKAGING     125   1339.789228  1351.280647  PACKAGING_LINE_1\n",
      "11   PACKAGING     152   1622.034899  1634.524703  PACKAGING_LINE_1\n",
      "12   PACKAGING     275   2772.379505  2788.579638  PACKAGING_LINE_3\n",
      "13   PACKAGING     346   3622.978353  3636.111059  PACKAGING_LINE_1\n",
      "14   PACKAGING     395   4100.077432  4103.419272  PACKAGING_LINE_3\n",
      "15     SORTING      92   1004.528489  1009.535639     SORTING_ROBOT\n",
      "16     SORTING     130   1397.882166  1411.493474     SORTING_ROBOT\n",
      "17     SORTING     149   1542.687457  1554.613012     SORTING_ROBOT\n",
      "18     SORTING     206   2117.899870  2119.895215     SORTING_ROBOT\n",
      "19     SORTING     211   2158.457808  2171.686444     SORTING_ROBOT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\990215322\\AppData\\Local\\Temp\\ipykernel_1768\\2571064504.py:53: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  visits = pd.concat(all_visits, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Load your file\n",
    "df = pd.read_csv(r'results\\FIFO_l0.1_actuator_manufacturing_with_rework.csv')\n",
    "\n",
    "# 1) Define arrival events per station (first + rework arrivals)\n",
    "ARRIVALS = {\n",
    "    \"MOULDING\":   [\"START\", \"QC_AFTER_MOULDING\"],     # first is START, rework from its own QC\n",
    "    \"ASSEMBLY_1\": [\"QC_AFTER_MOULDING\", \"QC_AFTER_ASSEMBLY1\"],\n",
    "    \"ASSEMBLY_2\": [\"QC_AFTER_ASSEMBLY1\", \"QC_AFTER_ASSEMBLY2\"],\n",
    "    \"SORTING\":    [\"QC_AFTER_ASSEMBLY2\", \"QC_AFTER_SORTING\"],\n",
    "    \"PACKAGING\":  [\"QC_AFTER_SORTING\", \"QC_AFTER_PACKAGING\"],\n",
    "}\n",
    "\n",
    "# If you ever run the dedicated-lane scenario, include lanes too:\n",
    "for i in range(1,6):\n",
    "    ARRIVALS[f\"ASSEMBLY_1_{i}\"] = [\"QC_AFTER_MOULDING\", f\"QC_AFTER_ASSEMBLY1_{i}\"]\n",
    "\n",
    "# 2) Build (arrival_time, start_time) **per visit** for each station and case\n",
    "def station_visits(df, station, arrival_labels):\n",
    "    # Starts at the station\n",
    "    starts = df[(df[\"status\"]==\"running\") & (df[\"activity\"]==station)] \\\n",
    "               .sort_values(\"timestamp\")[[\"case_id\",\"timestamp\",\"activity\",\"resource\"]] \\\n",
    "               .rename(columns={\"timestamp\":\"start_time\"})\n",
    "    if starts.empty:\n",
    "        return pd.DataFrame(columns=[\"case_id\",\"visit_idx\",\"arrival_time\",\"start_time\",\"station\",\"resource\"])\n",
    "\n",
    "    # All arrival events for this station\n",
    "    # START rows are status==\"START\"; QC rows are status==\"gateway\"\n",
    "    starts_evt = df[df[\"status\"]==\"START\"][[\"case_id\",\"timestamp\"]] \\\n",
    "                   .rename(columns={\"timestamp\":\"arrival_time\"}).assign(activity=\"START\")\n",
    "    qcs = df[(df[\"status\"]==\"gateway\") & (df[\"activity\"].isin(arrival_labels))] \\\n",
    "            [[\"case_id\",\"activity\",\"timestamp\"]].rename(columns={\"timestamp\":\"arrival_time\"})\n",
    "    arrivals = pd.concat([starts_evt[starts_evt[\"activity\"].isin(arrival_labels)], qcs], ignore_index=True)\n",
    "\n",
    "    # Keep only arrival rows for cases that actually start at this station\n",
    "    arrivals = arrivals[arrivals[\"case_id\"].isin(starts[\"case_id\"].unique())] \\\n",
    "                       .sort_values([\"case_id\",\"arrival_time\",\"activity\"]).copy()\n",
    "\n",
    "    # Number visits per case independently for arrivals and starts, then align by index\n",
    "    arrivals[\"visit_idx\"] = arrivals.groupby(\"case_id\").cumcount()\n",
    "    starts[\"visit_idx\"]   = starts.groupby(\"case_id\").cumcount()\n",
    "\n",
    "    m = starts.merge(arrivals[[\"case_id\",\"visit_idx\",\"arrival_time\"]],\n",
    "                     on=[\"case_id\",\"visit_idx\"], how=\"left\")\n",
    "    m[\"station\"] = station\n",
    "    return m\n",
    "\n",
    "all_visits = []\n",
    "for st, arr_labels in ARRIVALS.items():\n",
    "    all_visits.append(station_visits(df, st, arr_labels))\n",
    "visits = pd.concat(all_visits, ignore_index=True)\n",
    "\n",
    "# 3) FIFO test: in start order, the arrival_time must be non-decreasing (ties OK)\n",
    "fifo_results = []\n",
    "for st, g in visits.groupby(\"station\", sort=True):\n",
    "    g = g.sort_values(\"start_time\")\n",
    "    # Count strict violations: a later start has an earlier arrival than the previous start\n",
    "    violations = (g[\"arrival_time\"].diff().dropna() < 0).sum()\n",
    "    fifo_results.append((st, len(g), int(violations)))\n",
    "fifo_df = pd.DataFrame(fifo_results, columns=[\"station\",\"num_starts\",\"fifo_violations\"]).sort_values(\"station\")\n",
    "print(fifo_df)\n",
    "\n",
    "# 4) If any violations remain, show a few for inspection\n",
    "bad = []\n",
    "for st, g in visits.groupby(\"station\", sort=True):\n",
    "    g = g.sort_values(\"start_time\").reset_index(drop=True)\n",
    "    mask = g[\"arrival_time\"].diff() < 0\n",
    "    if mask.any():\n",
    "        out = g.loc[mask, [\"station\",\"case_id\",\"arrival_time\",\"start_time\",\"resource\"]].copy()\n",
    "        bad.append(out.head(5))\n",
    "if bad:\n",
    "    print(\"\\nSample suspected FIFO breaches (visit-aligned):\")\n",
    "    print(pd.concat(bad, ignore_index=True))\n",
    "else:\n",
    "    print(\"\\nNo FIFO breaches found with visit alignment.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ac5684ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      station  num_starts  fifo_violations\n",
      "0  ASSEMBLY_1         509               11\n",
      "1  ASSEMBLY_2         504               12\n",
      "2    MOULDING         510                0\n",
      "3   PACKAGING         503                5\n",
      "4     SORTING         500               10\n",
      "\n",
      "Sample suspected FIFO breaches (visit-aligned):\n",
      "       station case_id  arrival_time   start_time          resource\n",
      "0   ASSEMBLY_1      33    402.311682   411.599726  LINE_3_ASSEMBLY1\n",
      "1   ASSEMBLY_1     103   1102.818885  1113.767775  LINE_1_ASSEMBLY1\n",
      "2   ASSEMBLY_1     138   1455.327242  1465.529719  LINE_3_ASSEMBLY1\n",
      "3   ASSEMBLY_1     169   1773.614091  1776.680566  LINE_3_ASSEMBLY1\n",
      "4   ASSEMBLY_1     185   1856.545798  1861.188596  LINE_3_ASSEMBLY1\n",
      "5   ASSEMBLY_2      36    438.669189   443.125091  ASSEMBLY2_LINE_2\n",
      "6   ASSEMBLY_2      52    597.094904   599.170323  ASSEMBLY2_LINE_2\n",
      "7   ASSEMBLY_2      50    603.308664   614.308147  ASSEMBLY2_LINE_1\n",
      "8   ASSEMBLY_2     103   1113.767775  1130.550345  ASSEMBLY2_LINE_1\n",
      "9   ASSEMBLY_2     136   1428.722892  1437.719516  ASSEMBLY2_LINE_2\n",
      "10   PACKAGING     125   1339.789228  1351.280647  PACKAGING_LINE_1\n",
      "11   PACKAGING     152   1622.034899  1634.524703  PACKAGING_LINE_1\n",
      "12   PACKAGING     275   2772.379505  2788.579638  PACKAGING_LINE_3\n",
      "13   PACKAGING     346   3622.978353  3636.111059  PACKAGING_LINE_1\n",
      "14   PACKAGING     395   4100.077432  4103.419272  PACKAGING_LINE_3\n",
      "15     SORTING      92   1004.528489  1009.535639     SORTING_ROBOT\n",
      "16     SORTING     130   1397.882166  1411.493474     SORTING_ROBOT\n",
      "17     SORTING     149   1542.687457  1554.613012     SORTING_ROBOT\n",
      "18     SORTING     206   2117.899870  2119.895215     SORTING_ROBOT\n",
      "19     SORTING     211   2158.457808  2171.686444     SORTING_ROBOT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\990215322\\AppData\\Local\\Temp\\ipykernel_1768\\2571064504.py:53: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  visits = pd.concat(all_visits, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Load your file\n",
    "df = pd.read_csv(r'results\\FIFO_l0.1_actuator_manufacturing_with_rework.csv')\n",
    "\n",
    "# 1) Define arrival events per station (first + rework arrivals)\n",
    "ARRIVALS = {\n",
    "    \"MOULDING\":   [\"START\", \"QC_AFTER_MOULDING\"],     # first is START, rework from its own QC\n",
    "    \"ASSEMBLY_1\": [\"QC_AFTER_MOULDING\", \"QC_AFTER_ASSEMBLY1\"],\n",
    "    \"ASSEMBLY_2\": [\"QC_AFTER_ASSEMBLY1\", \"QC_AFTER_ASSEMBLY2\"],\n",
    "    \"SORTING\":    [\"QC_AFTER_ASSEMBLY2\", \"QC_AFTER_SORTING\"],\n",
    "    \"PACKAGING\":  [\"QC_AFTER_SORTING\", \"QC_AFTER_PACKAGING\"],\n",
    "}\n",
    "\n",
    "# If you ever run the dedicated-lane scenario, include lanes too:\n",
    "for i in range(1,6):\n",
    "    ARRIVALS[f\"ASSEMBLY_1_{i}\"] = [\"QC_AFTER_MOULDING\", f\"QC_AFTER_ASSEMBLY1_{i}\"]\n",
    "\n",
    "# 2) Build (arrival_time, start_time) **per visit** for each station and case\n",
    "def station_visits(df, station, arrival_labels):\n",
    "    # Starts at the station\n",
    "    starts = df[(df[\"status\"]==\"running\") & (df[\"activity\"]==station)] \\\n",
    "               .sort_values(\"timestamp\")[[\"case_id\",\"timestamp\",\"activity\",\"resource\"]] \\\n",
    "               .rename(columns={\"timestamp\":\"start_time\"})\n",
    "    if starts.empty:\n",
    "        return pd.DataFrame(columns=[\"case_id\",\"visit_idx\",\"arrival_time\",\"start_time\",\"station\",\"resource\"])\n",
    "\n",
    "    # All arrival events for this station\n",
    "    # START rows are status==\"START\"; QC rows are status==\"gateway\"\n",
    "    starts_evt = df[df[\"status\"]==\"START\"][[\"case_id\",\"timestamp\"]] \\\n",
    "                   .rename(columns={\"timestamp\":\"arrival_time\"}).assign(activity=\"START\")\n",
    "    qcs = df[(df[\"status\"]==\"gateway\") & (df[\"activity\"].isin(arrival_labels))] \\\n",
    "            [[\"case_id\",\"activity\",\"timestamp\"]].rename(columns={\"timestamp\":\"arrival_time\"})\n",
    "    arrivals = pd.concat([starts_evt[starts_evt[\"activity\"].isin(arrival_labels)], qcs], ignore_index=True)\n",
    "\n",
    "    # Keep only arrival rows for cases that actually start at this station\n",
    "    arrivals = arrivals[arrivals[\"case_id\"].isin(starts[\"case_id\"].unique())] \\\n",
    "                       .sort_values([\"case_id\",\"arrival_time\",\"activity\"]).copy()\n",
    "\n",
    "    # Number visits per case independently for arrivals and starts, then align by index\n",
    "    arrivals[\"visit_idx\"] = arrivals.groupby(\"case_id\").cumcount()\n",
    "    starts[\"visit_idx\"]   = starts.groupby(\"case_id\").cumcount()\n",
    "\n",
    "    m = starts.merge(arrivals[[\"case_id\",\"visit_idx\",\"arrival_time\"]],\n",
    "                     on=[\"case_id\",\"visit_idx\"], how=\"left\")\n",
    "    m[\"station\"] = station\n",
    "    return m\n",
    "\n",
    "all_visits = []\n",
    "for st, arr_labels in ARRIVALS.items():\n",
    "    all_visits.append(station_visits(df, st, arr_labels))\n",
    "visits = pd.concat(all_visits, ignore_index=True)\n",
    "\n",
    "# 3) FIFO test: in start order, the arrival_time must be non-decreasing (ties OK)\n",
    "fifo_results = []\n",
    "for st, g in visits.groupby(\"station\", sort=True):\n",
    "    g = g.sort_values(\"start_time\")\n",
    "    # Count strict violations: a later start has an earlier arrival than the previous start\n",
    "    violations = (g[\"arrival_time\"].diff().dropna() < 0).sum()\n",
    "    fifo_results.append((st, len(g), int(violations)))\n",
    "fifo_df = pd.DataFrame(fifo_results, columns=[\"station\",\"num_starts\",\"fifo_violations\"]).sort_values(\"station\")\n",
    "print(fifo_df)\n",
    "\n",
    "# 4) If any violations remain, show a few for inspection\n",
    "bad = []\n",
    "for st, g in visits.groupby(\"station\", sort=True):\n",
    "    g = g.sort_values(\"start_time\").reset_index(drop=True)\n",
    "    mask = g[\"arrival_time\"].diff() < 0\n",
    "    if mask.any():\n",
    "        out = g.loc[mask, [\"station\",\"case_id\",\"arrival_time\",\"start_time\",\"resource\"]].copy()\n",
    "        bad.append(out.head(5))\n",
    "if bad:\n",
    "    print(\"\\nSample suspected FIFO breaches (visit-aligned):\")\n",
    "    print(pd.concat(bad, ignore_index=True))\n",
    "else:\n",
    "    print(\"\\nNo FIFO breaches found with visit alignment.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e7e7d605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "status\n",
      "queued      2526\n",
      "gateway     2526\n",
      "running     2526\n",
      "START        477\n",
      "COMPLETE     476\n",
      "Name: count, dtype: int64\n",
      "      station  num_starts  fifo_violations\n",
      "0  ASSEMBLY_1         509                0\n",
      "1  ASSEMBLY_2         504                0\n",
      "2    MOULDING         510                0\n",
      "3   PACKAGING         503                0\n",
      "4     SORTING         500                0\n",
      "\n",
      "No FIFO breaches found using true queued times.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(r'results\\FIFO_l0.1_actuator_manufacturing_with_rework.csv')\n",
    "print(df['status'].value_counts())   # must include 'queued'\n",
    "\n",
    "# starts at stations\n",
    "starts = df[df[\"status\"]==\"running\"][[\"activity\",\"case_id\",\"timestamp\",\"resource\"]] \\\n",
    "           .rename(columns={\"timestamp\":\"start_time\"})\n",
    "# true station-arrivals\n",
    "queued = df[df[\"status\"]==\"queued\"][[\"activity\",\"case_id\",\"timestamp\"]] \\\n",
    "           .rename(columns={\"timestamp\":\"arrival_time\"})\n",
    "\n",
    "# visit-align per (activity, case_id)\n",
    "starts[\"visit_idx\"] = starts.groupby([\"activity\",\"case_id\"]).cumcount()\n",
    "queued[\"visit_idx\"] = queued.groupby([\"activity\",\"case_id\"]).cumcount()\n",
    "\n",
    "visits = starts.merge(queued, on=[\"activity\",\"case_id\",\"visit_idx\"], how=\"left\")\n",
    "\n",
    "rows, windows = [], []\n",
    "for st, g in visits.groupby(\"activity\", sort=True):\n",
    "    g = g.sort_values(\"start_time\").reset_index(drop=True)\n",
    "    diffs = g[\"arrival_time\"].diff()\n",
    "    violations = int((diffs < 0).sum())\n",
    "    rows.append((st, len(g), violations))\n",
    "    # collect small windows around violations to inspect\n",
    "    for i in g.index[diffs < 0][:5]:\n",
    "        lo, hi = max(0, i-1), min(len(g)-1, i+1)\n",
    "        windows.append(g.loc[lo:hi, [\"activity\",\"case_id\",\"arrival_time\",\"start_time\",\"resource\"]])\n",
    "\n",
    "fifo = pd.DataFrame(rows, columns=[\"station\",\"num_starts\",\"fifo_violations\"]).sort_values(\"station\")\n",
    "print(fifo)\n",
    "\n",
    "if windows:\n",
    "    print(\"\\nWindows around violations:\")\n",
    "    print(pd.concat(windows, ignore_index=True))\n",
    "else:\n",
    "    print(\"\\nNo FIFO breaches found using true queued times.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
