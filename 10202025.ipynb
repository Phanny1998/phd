{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84128f18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num task instances: 72378\n",
      "sample inst:\n",
      "    case_id    activity  queued_ts  start_ts     end_ts     resource_name\n",
      "0        0  ASSEMBLY_1   0.264408  0.264408  19.859716  LINE_1_ASSEMBLY1\n",
      "1        0  ASSEMBLY_1   3.680903  3.680903   5.773112  LINE_1_ASSEMBLY1\n",
      "2        0  ASSEMBLY_1   4.878237  4.878237   5.628757  LINE_1_ASSEMBLY1\n",
      "3        0  ASSEMBLY_1   6.279048  6.279048  15.493677  LINE_1_ASSEMBLY1\n",
      "4        0  ASSEMBLY_1   6.416882  6.416882   8.926294  LINE_1_ASSEMBLY1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 99\u001b[39m\n\u001b[32m     96\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mEND\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     97\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m np.nan\n\u001b[32m---> \u001b[39m\u001b[32m99\u001b[39m gates[\u001b[33m\"\u001b[39m\u001b[33mnext_activity\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[43m[\u001b[49m\n\u001b[32m    100\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnext_step_after_gateway\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    101\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgates\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcase_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrow_in_case\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitertuples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    102\u001b[39m \u001b[43m]\u001b[49m\n\u001b[32m    104\u001b[39m \u001b[38;5;66;03m# Empirical routing per gateway label\u001b[39;00m\n\u001b[32m    105\u001b[39m routing_emp = (\n\u001b[32m    106\u001b[39m     gates.groupby(\u001b[33m\"\u001b[39m\u001b[33mactivity\u001b[39m\u001b[33m\"\u001b[39m)[\u001b[33m\"\u001b[39m\u001b[33mnext_activity\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    107\u001b[39m          .value_counts(normalize=\u001b[38;5;28;01mTrue\u001b[39;00m, dropna=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    108\u001b[39m          .rename(\u001b[33m\"\u001b[39m\u001b[33mprob\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    109\u001b[39m          .reset_index()\n\u001b[32m    110\u001b[39m )\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 100\u001b[39m, in \u001b[36m<listcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m     96\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mEND\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     97\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m np.nan\n\u001b[32m     99\u001b[39m gates[\u001b[33m\"\u001b[39m\u001b[33mnext_activity\u001b[39m\u001b[33m\"\u001b[39m] = [\n\u001b[32m--> \u001b[39m\u001b[32m100\u001b[39m     \u001b[43mnext_step_after_gateway\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    101\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m cid, r \u001b[38;5;129;01min\u001b[39;00m gates[[\u001b[33m\"\u001b[39m\u001b[33mcase_id\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33mrow_in_case\u001b[39m\u001b[33m\"\u001b[39m]].itertuples(index=\u001b[38;5;28;01mFalse\u001b[39;00m, name=\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    102\u001b[39m ]\n\u001b[32m    104\u001b[39m \u001b[38;5;66;03m# Empirical routing per gateway label\u001b[39;00m\n\u001b[32m    105\u001b[39m routing_emp = (\n\u001b[32m    106\u001b[39m     gates.groupby(\u001b[33m\"\u001b[39m\u001b[33mactivity\u001b[39m\u001b[33m\"\u001b[39m)[\u001b[33m\"\u001b[39m\u001b[33mnext_activity\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    107\u001b[39m          .value_counts(normalize=\u001b[38;5;28;01mTrue\u001b[39;00m, dropna=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    108\u001b[39m          .rename(\u001b[33m\"\u001b[39m\u001b[33mprob\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    109\u001b[39m          .reset_index()\n\u001b[32m    110\u001b[39m )\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 87\u001b[39m, in \u001b[36mnext_step_after_gateway\u001b[39m\u001b[34m(case_id, row_idx_after)\u001b[39m\n\u001b[32m     80\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mnext_step_after_gateway\u001b[39m(case_id, row_idx_after):\n\u001b[32m     81\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     82\u001b[39m \u001b[33;03m    Return the 'next activity' chosen after a gateway for a given case, by scanning\u001b[39;00m\n\u001b[32m     83\u001b[39m \u001b[33;03m    the subsequent rows (in order) for that case:\u001b[39;00m\n\u001b[32m     84\u001b[39m \u001b[33;03m      - first 'queued' row -> its activity is the chosen branch\u001b[39;00m\n\u001b[32m     85\u001b[39m \u001b[33;03m      - if none and gateway was QC_AFTER_PACKAGING, treat next COMPLETE as END\u001b[39;00m\n\u001b[32m     86\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m87\u001b[39m     sub = df_sorted[(\u001b[43mdf_sorted\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcase_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[43mcase_id\u001b[49m) & (df_sorted[\u001b[33m\"\u001b[39m\u001b[33mrow_in_case\u001b[39m\u001b[33m\"\u001b[39m] > row_idx_after)]\n\u001b[32m     88\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m sub.empty:\n\u001b[32m     89\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m np.nan\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\990215322\\Desktop\\MuProMAC\\.venv\\Lib\\site-packages\\pandas\\core\\ops\\common.py:76\u001b[39m, in \u001b[36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[39m\u001b[34m(self, other)\u001b[39m\n\u001b[32m     72\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[32m     74\u001b[39m other = item_from_zerodim(other)\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\990215322\\Desktop\\MuProMAC\\.venv\\Lib\\site-packages\\pandas\\core\\arraylike.py:40\u001b[39m, in \u001b[36mOpsMixin.__eq__\u001b[39m\u001b[34m(self, other)\u001b[39m\n\u001b[32m     38\u001b[39m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m__eq__\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     39\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__eq__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_cmp_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[43m.\u001b[49m\u001b[43meq\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\990215322\\Desktop\\MuProMAC\\.venv\\Lib\\site-packages\\pandas\\core\\series.py:6138\u001b[39m, in \u001b[36mSeries._cmp_method\u001b[39m\u001b[34m(self, other, op)\u001b[39m\n\u001b[32m   6135\u001b[39m lvalues = \u001b[38;5;28mself\u001b[39m._values\n\u001b[32m   6136\u001b[39m rvalues = extract_array(other, extract_numpy=\u001b[38;5;28;01mTrue\u001b[39;00m, extract_range=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m6138\u001b[39m res_values = \u001b[43mops\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcomparison_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6140\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._construct_result(res_values, name=res_name)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\990215322\\Desktop\\MuProMAC\\.venv\\Lib\\site-packages\\pandas\\core\\ops\\array_ops.py:347\u001b[39m, in \u001b[36mcomparison_op\u001b[39m\u001b[34m(left, right, op)\u001b[39m\n\u001b[32m    344\u001b[39m     res_values = comp_method_OBJECT_ARRAY(op, lvalues, rvalues)\n\u001b[32m    346\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m347\u001b[39m     res_values = \u001b[43m_na_arithmetic_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_cmp\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    349\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m res_values\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\990215322\\Desktop\\MuProMAC\\.venv\\Lib\\site-packages\\pandas\\core\\ops\\array_ops.py:218\u001b[39m, in \u001b[36m_na_arithmetic_op\u001b[39m\u001b[34m(left, right, op, is_cmp)\u001b[39m\n\u001b[32m    215\u001b[39m     func = partial(expressions.evaluate, op)\n\u001b[32m    217\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m    220\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_cmp \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[32m    221\u001b[39m         left.dtype == \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(right, \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) == \u001b[38;5;28mobject\u001b[39m\n\u001b[32m    222\u001b[39m     ):\n\u001b[32m   (...)\u001b[39m\u001b[32m    225\u001b[39m         \u001b[38;5;66;03m# Don't do this for comparisons, as that will handle complex numbers\u001b[39;00m\n\u001b[32m    226\u001b[39m         \u001b[38;5;66;03m#  incorrectly, see GH#32047\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\990215322\\Desktop\\MuProMAC\\.venv\\Lib\\site-packages\\pandas\\core\\computation\\expressions.py:242\u001b[39m, in \u001b[36mevaluate\u001b[39m\u001b[34m(op, a, b, use_numexpr)\u001b[39m\n\u001b[32m    239\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m op_str \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    240\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m use_numexpr:\n\u001b[32m    241\u001b[39m         \u001b[38;5;66;03m# error: \"None\" not callable\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m242\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m    243\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _evaluate_standard(op, op_str, a, b)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\990215322\\Desktop\\MuProMAC\\.venv\\Lib\\site-packages\\pandas\\core\\computation\\expressions.py:73\u001b[39m, in \u001b[36m_evaluate_standard\u001b[39m\u001b[34m(op, op_str, a, b)\u001b[39m\n\u001b[32m     71\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _TEST_MODE:\n\u001b[32m     72\u001b[39m     _store_test_result(\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m op(a, b)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- Load ---\n",
    "df = pd.read_csv(\"results/251020FIFO_l0.28_actuator_manufacturing_with_rework.csv\")\n",
    "\n",
    "# Keep only relevant cols\n",
    "cols = [\"simulation_run\",\"timestamp\",\"status\",\"case_id\",\"activity\",\"resource\",\"end_time\",\"cycle_time\",\"data\",\"scenario\",\"l\",\"method\"]\n",
    "df = df[cols].copy()\n",
    "\n",
    "# Parse numeric\n",
    "df[\"timestamp\"] = pd.to_numeric(df[\"timestamp\"], errors=\"coerce\")\n",
    "df[\"end_time\"] = pd.to_numeric(df[\"end_time\"], errors=\"coerce\")\n",
    "\n",
    "# --- 1) basic schema sanity ---\n",
    "required = [\"timestamp\",\"status\",\"case_id\",\"activity\"]\n",
    "missing_cols = [c for c in required if c not in df.columns]\n",
    "assert not missing_cols, f\"Missing columns: {missing_cols}\"\n",
    "assert df[required].isnull().sum().sum() == 0, \"Nulls found in required fields\"\n",
    "\n",
    "# --- 2) reconstruct task instances (robust pairing) ---\n",
    "# Keep only task lifecycle rows (exclude gateways and START/COMPLETE for case)\n",
    "task_rows = df[df[\"activity\"].ne(\"START\") & df[\"status\"].isin([\"queued\",\"running\"])].copy()\n",
    "\n",
    "# Sort so cumcounts respect time\n",
    "task_rows = task_rows.sort_values([\"case_id\",\"activity\",\"timestamp\"]).copy()\n",
    "\n",
    "# Split and make occurrence indices *per status* (not mixed)\n",
    "queued = task_rows[task_rows[\"status\"]==\"queued\"].copy()\n",
    "queued[\"occ_q\"] = queued.groupby([\"case_id\",\"activity\"]).cumcount()\n",
    "\n",
    "running = task_rows[task_rows[\"status\"]==\"running\"].copy()\n",
    "running[\"occ_r\"] = running.groupby([\"case_id\",\"activity\"]).cumcount()\n",
    "\n",
    "# Merge kth queued with kth running for each (case, activity)\n",
    "inst = pd.merge(\n",
    "    queued[[\"case_id\",\"activity\",\"occ_q\",\"timestamp\"]].rename(columns={\"timestamp\":\"queued_ts\"}),\n",
    "    running[[\"case_id\",\"activity\",\"occ_r\",\"timestamp\",\"end_time\",\"resource\"]].rename(\n",
    "        columns={\"timestamp\":\"start_ts\",\"end_time\":\"end_ts\",\"resource\":\"resource_name\"}),\n",
    "    left_on=[\"case_id\",\"activity\",\"occ_q\"],\n",
    "    right_on=[\"case_id\",\"activity\",\"occ_r\"],\n",
    "    how=\"inner\",\n",
    ").drop(columns=[\"occ_q\",\"occ_r\"])\n",
    "\n",
    "print(\"num task instances:\", len(inst))\n",
    "print(\"sample inst:\\n\", inst.head())\n",
    "\n",
    "# Durations\n",
    "inst[\"wait\"] = inst[\"start_ts\"] - inst[\"queued_ts\"]\n",
    "inst[\"service\"] = inst[\"end_ts\"] - inst[\"start_ts\"]\n",
    "inst[\"sojourn\"] = inst[\"end_ts\"] - inst[\"queued_ts\"]\n",
    "\n",
    "# Sanity: no negatives\n",
    "neg = inst[(inst[\"wait\"]<0) | (inst[\"service\"]<0) | (inst[\"sojourn\"]<0)]\n",
    "assert neg.empty, f\"Negative times found:\\n{neg.head()}\"\n",
    "\n",
    "\n",
    "# --- 3) FIFO discipline per station (warning-free) ---\n",
    "tmp = inst.sort_values([\"activity\",\"queued_ts\",\"start_ts\"]).copy()\n",
    "eps = 1e-9\n",
    "tmp[\"dec\"] = tmp.groupby(\"activity\")[\"start_ts\"].diff() < -eps\n",
    "\n",
    "fifo_check = (\n",
    "    tmp.groupby(\"activity\", as_index=False)\n",
    "       .agg(num_instances=(\"start_ts\",\"size\"),\n",
    "            fifo_violations=(\"dec\",\"sum\"))\n",
    ")\n",
    "fifo_check[\"fifo_violations\"] = fifo_check[\"fifo_violations\"].astype(int)\n",
    "\n",
    "# --- 4) routing/QC probabilities (position-based, handles same-timestamp + END) ---\n",
    "\n",
    "# Sort by case then time, and give each row an order within the case\n",
    "df_sorted = df.sort_values([\"case_id\", \"timestamp\"]).copy()\n",
    "df_sorted[\"row_in_case\"] = df_sorted.groupby(\"case_id\").cumcount()\n",
    "\n",
    "# Grab gateway rows (after they have row_in_case)\n",
    "gates = df_sorted[df_sorted[\"status\"] == \"gateway\"][[\"case_id\",\"timestamp\",\"activity\",\"row_in_case\"]].copy()\n",
    "gates = gates.sort_values([\"case_id\",\"row_in_case\"]).reset_index(drop=True)\n",
    "\n",
    "def next_step_after_gateway(case_id, row_idx_after):\n",
    "    \"\"\"\n",
    "    Return the 'next activity' chosen after a gateway for a given case, by scanning\n",
    "    the subsequent rows (in order) for that case:\n",
    "      - first 'queued' row -> its activity is the chosen branch\n",
    "      - if none and gateway was QC_AFTER_PACKAGING, treat next COMPLETE as END\n",
    "    \"\"\"\n",
    "    sub = df_sorted[(df_sorted[\"case_id\"] == case_id) & (df_sorted[\"row_in_case\"] > row_idx_after)]\n",
    "    if sub.empty:\n",
    "        return np.nan\n",
    "    nxt_q = sub.loc[sub[\"status\"] == \"queued\"]\n",
    "    if not nxt_q.empty:\n",
    "        return nxt_q.iloc[0][\"activity\"]\n",
    "    # No queued afterwards; for packaging gateway the case may complete next\n",
    "    nxt_c = sub.loc[sub[\"status\"] == \"COMPLETE\"]\n",
    "    if not nxt_c.empty:\n",
    "        return \"END\"\n",
    "    return np.nan\n",
    "\n",
    "gates[\"next_activity\"] = [\n",
    "    next_step_after_gateway(cid, r)\n",
    "    for cid, r in gates[[\"case_id\",\"row_in_case\"]].itertuples(index=False, name=None)\n",
    "]\n",
    "\n",
    "# Empirical routing per gateway label\n",
    "routing_emp = (\n",
    "    gates.groupby(\"activity\")[\"next_activity\"]\n",
    "         .value_counts(normalize=True, dropna=True)\n",
    "         .rename(\"prob\")\n",
    "         .reset_index()\n",
    ")\n",
    "\n",
    "# Expected (from your config)\n",
    "expected = {\n",
    "    \"QC_AFTER_MOULDING\":  {\"MOULDING\": 0.05, \"ASSEMBLY_1\": 0.95},\n",
    "    \"QC_AFTER_ASSEMBLY1\": {\"ASSEMBLY_1\": 0.05, \"ASSEMBLY_2\": 0.95},\n",
    "    \"QC_AFTER_ASSEMBLY2\": {\"ASSEMBLY_2\": 0.05, \"SORTING\":    0.95},\n",
    "    \"QC_AFTER_SORTING\":   {\"SORTING\":   0.05, \"PACKAGING\":   0.95},\n",
    "    \"QC_AFTER_PACKAGING\": {\"PACKAGING\": 0.05, \"END\":         0.95},\n",
    "}\n",
    "routing_exp = pd.DataFrame(\n",
    "    [{\"activity\": g, \"next_activity\": nxt, \"expected\": p}\n",
    "     for g, dd in expected.items() for nxt, p in dd.items()]\n",
    ")\n",
    "\n",
    "routing = (routing_exp\n",
    "           .merge(routing_emp, on=[\"activity\",\"next_activity\"], how=\"left\")\n",
    "           .fillna({\"prob\": 0.0}))\n",
    "routing[\"diff\"] = routing[\"prob\"] - routing[\"expected\"]\n",
    "\n",
    "print(\"\\nRouting empirical vs expected (position-based):\")\n",
    "print(routing.sort_values([\"activity\",\"next_activity\"]))\n",
    "\n",
    "# How many gateways had 0-wait to the next station?\n",
    "merge_for_wait = gates.merge(\n",
    "    inst[[\"case_id\",\"activity\",\"queued_ts\",\"start_ts\"]],\n",
    "    left_on=[\"case_id\",\"next_activity\"], right_on=[\"case_id\",\"activity\"],\n",
    "    how=\"left\", suffixes=(\"_gate\",\"_next\")\n",
    ")\n",
    "zero_wait_share = (merge_for_wait[\"start_ts\"] - merge_for_wait[\"timestamp\"] <= 1e-9).mean()\n",
    "print(\"Share of gateways with immediate (zero-wait) handoff:\", zero_wait_share)\n",
    "\n",
    "\n",
    "# --- 5) service-time by resource ---\n",
    "svc = inst.dropna(subset=[\"resource_name\",\"service\"]).copy()\n",
    "svc_stats = svc.groupby(\"resource_name\")[\"service\"].agg([\"count\",\"mean\",\"std\",\"min\",\"max\"]).reset_index()\n",
    "\n",
    "# Rough exponential check: for Exp, mean ≈ std; ratio near 1 is indicative (not proof)\n",
    "svc_stats[\"std_over_mean\"] = svc_stats[\"std\"]/svc_stats[\"mean\"]\n",
    "\n",
    "# --- 6) utilization & throughput ---\n",
    "T = df[\"timestamp\"].max()  # sim horizon (approx)\n",
    "busy = (\n",
    "    svc.groupby(\"resource_name\", as_index=False)[\"service\"]\n",
    "       .sum()\n",
    "       .rename(columns={\"service\":\"busy_time\"})\n",
    ")\n",
    "busy[\"utilization\"] = busy[\"busy_time\"] / T\n",
    "\n",
    "# Station-level KPIs\n",
    "station = inst.groupby(\"activity\").agg(\n",
    "    arrivals=(\"activity\",\"size\"),\n",
    "    mean_wait=(\"wait\",\"mean\"),\n",
    "    mean_service=(\"service\",\"mean\"),\n",
    "    mean_sojourn=(\"sojourn\",\"mean\")\n",
    ").reset_index()\n",
    "\n",
    "# --- 7) Little's Law check: L ≈ λ W at station level ---\n",
    "# λ = arrivals / T; W = mean_sojourn at station; L_hat = λ*W\n",
    "station[\"lambda\"] = station[\"arrivals\"] / T\n",
    "station[\"L_hat\"] = station[\"lambda\"] * station[\"mean_sojourn\"]\n",
    "\n",
    "# (Optional, time-weighted L from queue-length trace would be more exact.)\n",
    "\n",
    "# --- Summaries to print or save ---\n",
    "print(\"\\nFIFO violations per station (should be 0):\")\n",
    "print(fifo_check.sort_values(\"fifo_violations\", ascending=False).head(10))\n",
    "\n",
    "print(\"\\nRouting empirical vs expected (diff near 0):\")\n",
    "print(routing.sort_values([\"activity\",\"next_activity\"]))\n",
    "\n",
    "print(\"\\nService by resource (std/mean ~ 1 for Exp):\")\n",
    "print(svc_stats.sort_values(\"std_over_mean\"))\n",
    "\n",
    "print(\"\\nResource utilization (sanity):\")\n",
    "print(busy.sort_values(\"utilization\", ascending=False).head(10))\n",
    "\n",
    "print(\"\\nStation KPIs + Little's Law proxy:\")\n",
    "print(station.sort_values(\"L_hat\", ascending=False).head(10))\n",
    "\n",
    "# --- Stability audit: capacity vs offered load, with warm-up trim ---\n",
    "\n",
    "warmup = df[\"timestamp\"].max() * 0.05  # trim first 5% to reduce transient bias\n",
    "inst_ss = inst[inst[\"queued_ts\"] >= warmup].copy()\n",
    "\n",
    "# Per-station arrival rate λ_station (jobs/min)\n",
    "T_eff = df[\"timestamp\"].max() - warmup\n",
    "arrivals = inst_ss.groupby(\"activity\")[\"activity\"].size().rename(\"arrivals\").reset_index()\n",
    "arrivals[\"lambda_station\"] = arrivals[\"arrivals\"] / T_eff\n",
    "\n",
    "# Mean service time per (activity, resource) then aggregate to station capacity\n",
    "svc_ss = inst_ss.dropna(subset=[\"resource_name\",\"service\"]).copy()\n",
    "rs = (svc_ss.groupby([\"activity\",\"resource_name\"])[\"service\"]\n",
    "            .mean()\n",
    "            .rename(\"mean_service\")\n",
    "            .reset_index())\n",
    "\n",
    "# Station capacity (jobs/min) = sum over resources of 1 / E[S_resource]\n",
    "cap = (rs.assign(mu=lambda d: 1.0 / d[\"mean_service\"])\n",
    "         .groupby(\"activity\")[\"mu\"].sum()\n",
    "         .rename(\"capacity\")\n",
    "         .reset_index())\n",
    "\n",
    "# Merge and compute utilization proxy and safety margin\n",
    "stab = (arrivals.merge(cap, on=\"activity\", how=\"left\"))\n",
    "stab[\"rho_hat\"] = stab[\"lambda_station\"] / stab[\"capacity\"]\n",
    "stab[\"headroom\"] = 1.0 - stab[\"rho_hat\"]\n",
    "\n",
    "print(\"\\nStability headroom by station (ρ_hat < 1 is required; aim for headroom ≥ 0.05):\")\n",
    "print(stab.sort_values(\"rho_hat\", ascending=False))\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def queue_trace(inst_df, act):\n",
    "    g = inst_df[inst_df[\"activity\"]==act][[\"queued_ts\",\"start_ts\"]].copy()\n",
    "    if g.empty: \n",
    "        return None\n",
    "    ups   = g.groupby(\"queued_ts\").size().rename(\"delta\")\n",
    "    downs = (g.groupby(\"start_ts\").size() * -1).rename(\"delta\")\n",
    "    deltas = pd.concat([ups, downs], axis=0).groupby(level=0).sum().sort_index()\n",
    "    tr = deltas.cumsum().reset_index().rename(columns={\"index\":\"time\",\"delta\":\"qlen\"})\n",
    "    tr[\"qlen\"] = tr[\"qlen\"].clip(lower=0)\n",
    "    return tr\n",
    "\n",
    "def end_trend_slope(trace, tail_frac=0.2):\n",
    "    if trace is None or len(trace) < 5: \n",
    "        return np.nan\n",
    "    n0 = int(len(trace)*(1-tail_frac))\n",
    "    tail = trace.iloc[max(n0,0):].copy()\n",
    "    if len(tail) < 3: \n",
    "        return np.nan\n",
    "    # simple least-squares slope of qlen on time\n",
    "    x = tail[\"time\"].values\n",
    "    y = tail[\"qlen\"].values\n",
    "    A = np.vstack([x, np.ones_like(x)]).T\n",
    "    slope, _ = np.linalg.lstsq(A, y, rcond=None)[0]\n",
    "    return slope  # jobs per minute near the end\n",
    "\n",
    "acts = sorted(inst_ss[\"activity\"].unique())\n",
    "trend = []\n",
    "for act in acts:\n",
    "    tr = queue_trace(inst_ss, act)\n",
    "    slope = end_trend_slope(tr, tail_frac=0.3)  # check last 30% of events\n",
    "    trend.append({\"activity\": act, \"end_slope_q_per_min\": slope})\n",
    "\n",
    "trend_df = pd.DataFrame(trend).sort_values(\"end_slope_q_per_min\", ascending=False)\n",
    "print(\"\\nQueue end-trend slope (jobs/min; ≈0 is good; persistently >0 indicates growing backlog):\")\n",
    "print(trend_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e34e508",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d15ab5ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== FIFO violations per run (should be all zeros) ===\n",
      "activity        ASSEMBLY_1  ASSEMBLY_2  MOULDING  PACKAGING  SORTING\n",
      "simulation_run                                                      \n",
      "0                      0.0         0.0       0.0        0.0      0.0\n",
      "1                      0.0         0.0       0.0        0.0      0.0\n",
      "2                      0.0         0.0       0.0        0.0      0.0\n",
      "3                      0.0         0.0       0.0        0.0      0.0\n",
      "4                      0.0         0.0       0.0        0.0      0.0\n",
      "5                      0.0         0.0       0.0        0.0      0.0\n",
      "6                      0.0         0.0       0.0        0.0      0.0\n",
      "7                      0.0         0.0       0.0        0.0      0.0\n",
      "8                      0.0         0.0       0.0        0.0      0.0\n",
      "9                      0.0         0.0       0.0        0.0      0.0\n",
      "\n",
      "=== Routing diff from expected (mean ± std across runs) ===\n",
      "             activity next_activity  diff_mean  diff_std\n",
      "0  QC_AFTER_ASSEMBLY1    ASSEMBLY_1  -0.000166  0.005445\n",
      "1  QC_AFTER_ASSEMBLY1    ASSEMBLY_2   0.000166  0.005445\n",
      "2  QC_AFTER_ASSEMBLY2    ASSEMBLY_2  -0.000223  0.007393\n",
      "3  QC_AFTER_ASSEMBLY2       SORTING   0.000223  0.007393\n",
      "4   QC_AFTER_MOULDING    ASSEMBLY_1  -0.002760  0.006260\n",
      "5   QC_AFTER_MOULDING      MOULDING   0.002760  0.006260\n",
      "6  QC_AFTER_PACKAGING           END  -0.003011  0.006448\n",
      "7  QC_AFTER_PACKAGING     PACKAGING   0.003011  0.006448\n",
      "8    QC_AFTER_SORTING     PACKAGING  -0.000971  0.006342\n",
      "9    QC_AFTER_SORTING       SORTING   0.000971  0.006342\n",
      "\n",
      "=== Stability headroom: bottleneck per run and min headroom ===\n",
      "    simulation_run  bottleneck   rho_hat  headroom\n",
      "1                0  ASSEMBLY_2  0.950427  0.049573\n",
      "6                1  ASSEMBLY_2  0.909684  0.090316\n",
      "14               2     SORTING  0.874133  0.125867\n",
      "19               3     SORTING  0.933641  0.066359\n",
      "21               4  ASSEMBLY_2  0.840079  0.159921\n",
      "26               5  ASSEMBLY_2  0.899549  0.100451\n",
      "31               6  ASSEMBLY_2  0.818181  0.181819\n",
      "39               7     SORTING  0.952070  0.047930\n",
      "41               8  ASSEMBLY_2  0.917422  0.082578\n",
      "49               9     SORTING  0.903020  0.096980\n",
      "Min headroom across runs: 0.047929694464979966\n",
      "\n",
      "=== Queue end-trend slopes (mean across runs; ≈0 is good) ===\n",
      "activity\n",
      "MOULDING     -0.000003\n",
      "ASSEMBLY_1   -0.000013\n",
      "PACKAGING    -0.000053\n",
      "SORTING      -0.001760\n",
      "ASSEMBLY_2   -0.002154\n",
      "Name: end_slope_q_per_min, dtype: float64\n",
      "\n",
      "=== Wait quantiles (p50/p90/p95) averaged across runs ===\n",
      "               p50     p90     p95\n",
      "activity                          \n",
      "ASSEMBLY_1   0.000   0.000   0.426\n",
      "ASSEMBLY_2  12.257  46.519  57.260\n",
      "MOULDING     0.000   0.000   0.000\n",
      "PACKAGING    0.000   0.666   2.252\n",
      "SORTING     12.363  38.200  49.799\n",
      "\n",
      "=== Starts vs Completes (case-trimmed) ===\n",
      "                n_start  n_complete  match\n",
      "simulation_run                            \n",
      "0                  1217        1217   True\n",
      "1                  1204        1204   True\n",
      "2                  1218        1218   True\n",
      "3                  1205        1205   True\n",
      "4                  1143        1143   True\n",
      "5                  1193        1193   True\n",
      "6                  1108        1108   True\n",
      "7                  1268        1268   True\n",
      "8                  1211        1211   True\n",
      "9                  1225        1225   True\n",
      "All runs balanced: True\n",
      "Cycle-time max abs diff: 2.2737367544323206e-12\n"
     ]
    }
   ],
   "source": [
    "# ============================ CONFIG ============================\n",
    "GLOB_PATTERN   = \"results/251020FIFO_l0.28_actuator_manufacturing_with_rework.csv\"\n",
    "WARMUP_FRAC    = 0.10   # 10% warm-up for steady-state metrics\n",
    "COOLDOWN_FRAC  = 0.02   # 2% tail trim\n",
    "EPS            = 1e-9\n",
    "SAVE_DISCOVERY = False  # set True to save case-trimmed discovery log\n",
    "DISCOVERY_OUT  = \"results/discovery_steady_state.csv\"\n",
    "# ===============================================================\n",
    "\n",
    "import pandas as pd, numpy as np, glob, os\n",
    "\n",
    "# ---------- Load ----------\n",
    "files = glob.glob(GLOB_PATTERN)\n",
    "if not files:\n",
    "    raise FileNotFoundError(f\"No files matched: {GLOB_PATTERN}\")\n",
    "\n",
    "df = pd.concat([pd.read_csv(p) for p in files], ignore_index=True)\n",
    "# types\n",
    "df[\"timestamp\"]      = pd.to_numeric(df[\"timestamp\"], errors=\"coerce\")\n",
    "df[\"end_time\"]       = pd.to_numeric(df.get(\"end_time\"), errors=\"coerce\")\n",
    "df[\"simulation_run\"] = pd.to_numeric(df[\"simulation_run\"], errors=\"coerce\").fillna(0).astype(int)\n",
    "\n",
    "# unique case key across runs\n",
    "df[\"global_case_id\"] = df[\"simulation_run\"].astype(str) + \"-\" + df[\"case_id\"].astype(str)\n",
    "\n",
    "# ---------- Helpers ----------\n",
    "expected = {\n",
    "    \"QC_AFTER_MOULDING\":  {\"MOULDING\": 0.05, \"ASSEMBLY_1\": 0.95},\n",
    "    \"QC_AFTER_ASSEMBLY1\": {\"ASSEMBLY_1\": 0.05, \"ASSEMBLY_2\": 0.95},\n",
    "    \"QC_AFTER_ASSEMBLY2\": {\"ASSEMBLY_2\": 0.05, \"SORTING\":    0.95},\n",
    "    \"QC_AFTER_SORTING\":   {\"SORTING\":   0.05, \"PACKAGING\":   0.95},\n",
    "    \"QC_AFTER_PACKAGING\": {\"PACKAGING\": 0.05, \"END\":         0.95},\n",
    "}\n",
    "routing_exp = pd.DataFrame(\n",
    "    [{\"activity\": g, \"next_activity\": nxt, \"expected\": p}\n",
    "     for g, dd in expected.items() for nxt, p in dd.items()]\n",
    ")\n",
    "\n",
    "def pair_instances(df_run):\n",
    "    \"\"\"Robust queued↔running pairing per (case, activity, occurrence).\"\"\"\n",
    "    tr = df_run[(df_run[\"activity\"].ne(\"START\")) &\n",
    "                (df_run[\"status\"].isin([\"queued\",\"running\"]))].copy()\n",
    "    tr = tr.sort_values([\"case_id\",\"activity\",\"timestamp\"])\n",
    "\n",
    "    q = tr[tr[\"status\"]==\"queued\"].copy()\n",
    "    q[\"occ_q\"] = q.groupby([\"case_id\",\"activity\"]).cumcount()\n",
    "\n",
    "    r = tr[tr[\"status\"]==\"running\"].copy()\n",
    "    r[\"occ_r\"] = r.groupby([\"case_id\",\"activity\"]).cumcount()\n",
    "\n",
    "    inst = pd.merge(\n",
    "        q[[\"case_id\",\"activity\",\"occ_q\",\"timestamp\"]].rename(columns={\"timestamp\":\"queued_ts\"}),\n",
    "        r[[\"case_id\",\"activity\",\"occ_r\",\"timestamp\",\"end_time\",\"resource\"]].rename(\n",
    "            columns={\"timestamp\":\"start_ts\",\"end_time\":\"end_ts\",\"resource\":\"resource_name\"}),\n",
    "        left_on=[\"case_id\",\"activity\",\"occ_q\"],\n",
    "        right_on=[\"case_id\",\"activity\",\"occ_r\"],\n",
    "        how=\"inner\",\n",
    "    ).drop(columns=[\"occ_q\",\"occ_r\"])\n",
    "\n",
    "    inst[\"wait\"]    = inst[\"start_ts\"] - inst[\"queued_ts\"]\n",
    "    inst[\"service\"] = inst[\"end_ts\"]   - inst[\"start_ts\"]\n",
    "    inst[\"sojourn\"] = inst[\"end_ts\"]   - inst[\"queued_ts\"]\n",
    "    return inst\n",
    "\n",
    "def fifo_violations(inst):\n",
    "    \"\"\"Check monotone nondecreasing start_ts after sorting by queued_ts.\"\"\"\n",
    "    if inst.empty:\n",
    "        return pd.DataFrame({\"activity\": [], \"fifo_violations\": []})\n",
    "    tmp = inst.sort_values([\"activity\",\"queued_ts\",\"start_ts\"]).copy()\n",
    "    tmp[\"dec\"] = tmp.groupby(\"activity\")[\"start_ts\"].diff() < -EPS\n",
    "    return (tmp.groupby(\"activity\")[\"dec\"].sum()\n",
    "               .astype(int).rename(\"fifo_violations\").reset_index())\n",
    "\n",
    "def routing_empirical(df_run):\n",
    "    \"\"\"Position-based extractor with END handling.\"\"\"\n",
    "    s = df_run.sort_values([\"case_id\",\"timestamp\"]).copy()\n",
    "    s[\"row_in_case\"] = s.groupby(\"case_id\").cumcount()\n",
    "    gates = s[s[\"status\"]==\"gateway\"][[\"case_id\",\"timestamp\",\"activity\",\"row_in_case\"]].copy()\n",
    "\n",
    "    def next_step(case_id, row_after):\n",
    "        sub = s[(s[\"case_id\"]==case_id) & (s[\"row_in_case\"]>row_after)]\n",
    "        if sub.empty: return np.nan\n",
    "        nxtq = sub.loc[sub[\"status\"]==\"queued\"]\n",
    "        if not nxtq.empty: return nxtq.iloc[0][\"activity\"]\n",
    "        nxtc = sub.loc[sub[\"status\"]==\"COMPLETE\"]\n",
    "        if not nxtc.empty: return \"END\"\n",
    "        return np.nan\n",
    "\n",
    "    if gates.empty:\n",
    "        out = routing_exp.copy()\n",
    "        out[\"prob\"] = np.nan\n",
    "        out[\"diff\"] = np.nan\n",
    "        return out\n",
    "\n",
    "    gates[\"next_activity\"] = [next_step(cid, r)\n",
    "                              for cid, r in gates[[\"case_id\",\"row_in_case\"]].itertuples(index=False, name=None)]\n",
    "    emp = (gates.groupby(\"activity\")[\"next_activity\"]\n",
    "                 .value_counts(normalize=True, dropna=True)\n",
    "                 .rename(\"prob\").reset_index())\n",
    "    rout = (routing_exp.merge(emp, on=[\"activity\",\"next_activity\"], how=\"left\")\n",
    "                      .fillna({\"prob\":0.0}))\n",
    "    rout[\"diff\"] = rout[\"prob\"] - rout[\"expected\"]\n",
    "    return rout\n",
    "\n",
    "def capacity_headroom(inst_ss, df_run_ss):\n",
    "    \"\"\"λ_station vs capacity (sum of per-resource μ̂).\"\"\"\n",
    "    if inst_ss.empty or df_run_ss.empty:\n",
    "        return pd.DataFrame(columns=[\"activity\",\"arrivals\",\"lambda_station\",\"capacity\",\"rho_hat\",\"headroom\"])\n",
    "    # arrivals per station in steady-state window\n",
    "    T_eff = df_run_ss[\"timestamp\"].max() - df_run_ss[\"timestamp\"].min()\n",
    "    arr = (inst_ss.groupby(\"activity\")[\"activity\"].size()\n",
    "           .rename(\"arrivals\").reset_index())\n",
    "    arr[\"lambda_station\"] = arr[\"arrivals\"] / max(T_eff, EPS)\n",
    "\n",
    "    # capacity via per-resource μ̂ = n / busy_time\n",
    "    svc = inst_ss.dropna(subset=[\"resource_name\",\"service\"]).copy()\n",
    "    rt = (svc.groupby([\"activity\",\"resource_name\"])[\"service\"]\n",
    "              .agg(n=\"size\", busy=\"sum\").reset_index())\n",
    "    rt[\"mu_hat\"] = rt[\"n\"] / rt[\"busy\"]\n",
    "    cap = (rt.groupby(\"activity\")[\"mu_hat\"].sum()\n",
    "             .rename(\"capacity\").reset_index())\n",
    "\n",
    "    stab = arr.merge(cap, on=\"activity\", how=\"left\")\n",
    "    stab[\"rho_hat\"] = stab[\"lambda_station\"] / stab[\"capacity\"]\n",
    "    stab[\"headroom\"] = 1 - stab[\"rho_hat\"]\n",
    "    return stab\n",
    "\n",
    "def queue_end_trend(inst_ss, tail_frac=0.3):\n",
    "    \"\"\"Least-squares slope of qlen over time on last fraction; ~0 means stable.\"\"\"\n",
    "    def qtrace(act):\n",
    "        g = inst_ss[inst_ss[\"activity\"]==act][[\"queued_ts\",\"start_ts\"]].copy()\n",
    "        if g.empty: return None\n",
    "        ups   = g.groupby(\"queued_ts\").size().rename(\"d\")\n",
    "        downs = (g.groupby(\"start_ts\").size()*-1).rename(\"d\")\n",
    "        deltas = pd.concat([ups, downs], axis=0).groupby(level=0).sum().sort_index()\n",
    "        tr = deltas.cumsum().reset_index().rename(columns={\"index\":\"time\", \"d\":\"qlen\"})\n",
    "        tr[\"qlen\"] = tr[\"qlen\"].clip(lower=0)\n",
    "        return tr\n",
    "\n",
    "    rows=[]\n",
    "    for act in sorted(inst_ss[\"activity\"].unique()):\n",
    "        tr = qtrace(act)\n",
    "        if tr is None or len(tr)<5:\n",
    "            rows.append({\"activity\":act, \"end_slope_q_per_min\": np.nan})\n",
    "            continue\n",
    "        n0 = int(len(tr)*(1-tail_frac))\n",
    "        tail = tr.iloc[max(n0,0):]\n",
    "        x = tail[\"time\"].values; y = tail[\"qlen\"].values\n",
    "        A = np.vstack([x, np.ones_like(x)]).T\n",
    "        slope, _ = np.linalg.lstsq(A, y, rcond=None)[0]\n",
    "        rows.append({\"activity\":act, \"end_slope_q_per_min\": slope})\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "# ---------- Per-run audits ----------\n",
    "per_run = []\n",
    "\n",
    "for run, df_run in df.groupby(\"simulation_run\", sort=True):\n",
    "    t_max = df_run[\"timestamp\"].max()\n",
    "    t0 = t_max*WARMUP_FRAC\n",
    "    t1 = t_max*(1-COOLDOWN_FRAC)\n",
    "\n",
    "    # steady-state event window for metrics\n",
    "    df_run_ss_events = df_run[(df_run[\"timestamp\"]>=t0) & (df_run[\"timestamp\"]<=t1)].copy()\n",
    "\n",
    "    # robust pairing on full run; then trim by queued_ts for SS\n",
    "    inst_full = pair_instances(df_run)\n",
    "    inst_ss   = inst_full[inst_full[\"queued_ts\"]>=t0].copy()\n",
    "\n",
    "    # audits\n",
    "    fifo   = fifo_violations(inst_ss);     fifo[\"simulation_run\"] = run\n",
    "    rout   = routing_empirical(df_run_ss_events); rout[\"simulation_run\"] = run\n",
    "    stab   = capacity_headroom(inst_ss, df_run_ss_events); stab[\"simulation_run\"] = run\n",
    "    slope  = queue_end_trend(inst_ss, tail_frac=0.3); slope[\"simulation_run\"] = run\n",
    "\n",
    "    # waits (quantiles) per station\n",
    "    waits = (inst_ss.groupby(\"activity\")[\"wait\"]\n",
    "             .quantile([0.5,0.9,0.95]).unstack().rename(columns={0.5:\"p50\",0.9:\"p90\",0.95:\"p95\"})\n",
    "             .reset_index())\n",
    "    waits[\"simulation_run\"] = run\n",
    "\n",
    "    per_run.append((fifo, rout, stab, slope, waits))\n",
    "\n",
    "fifo_all   = pd.concat([x[0] for x in per_run], ignore_index=True)\n",
    "routing_all= pd.concat([x[1] for x in per_run], ignore_index=True)\n",
    "stab_all   = pd.concat([x[2] for x in per_run], ignore_index=True)\n",
    "slope_all  = pd.concat([x[3] for x in per_run], ignore_index=True)\n",
    "waits_all  = pd.concat([x[4] for x in per_run], ignore_index=True)\n",
    "\n",
    "# ---------- Print summaries ----------\n",
    "print(\"\\n=== FIFO violations per run (should be all zeros) ===\")\n",
    "if fifo_all.empty:\n",
    "    print(\"No task instances in steady-state window.\")\n",
    "else:\n",
    "    print(fifo_all.pivot_table(index=\"simulation_run\", columns=\"activity\", values=\"fifo_violations\", fill_value=0))\n",
    "\n",
    "print(\"\\n=== Routing diff from expected (mean ± std across runs) ===\")\n",
    "routing_sum = (routing_all\n",
    "               .groupby([\"activity\",\"next_activity\"])\n",
    "               .agg(diff_mean=(\"diff\",\"mean\"), diff_std=(\"diff\",\"std\"))\n",
    "               .reset_index()\n",
    "               .sort_values([\"activity\",\"next_activity\"]))\n",
    "print(routing_sum)\n",
    "\n",
    "print(\"\\n=== Stability headroom: bottleneck per run and min headroom ===\")\n",
    "bot = (stab_all.sort_values([\"simulation_run\",\"rho_hat\"], ascending=[True,False])\n",
    "               .groupby(\"simulation_run\").head(1)\n",
    "               .rename(columns={\"activity\":\"bottleneck\"}))\n",
    "print(bot[[\"simulation_run\",\"bottleneck\",\"rho_hat\",\"headroom\"]])\n",
    "if not bot.empty:\n",
    "    print(\"Min headroom across runs:\", bot[\"headroom\"].min())\n",
    "\n",
    "print(\"\\n=== Queue end-trend slopes (mean across runs; ≈0 is good) ===\")\n",
    "print(slope_all.groupby(\"activity\")[\"end_slope_q_per_min\"].mean().sort_values(ascending=False))\n",
    "\n",
    "print(\"\\n=== Wait quantiles (p50/p90/p95) averaged across runs ===\")\n",
    "print(waits_all.groupby(\"activity\")[[\"p50\",\"p90\",\"p95\"]].mean().round(3))\n",
    "\n",
    "# ---------- Extra consistency checks (starts==completes, cycle time) ----------\n",
    "print(\"\\n=== Starts vs Completes (case-trimmed) ===\")\n",
    "# case-level metadata\n",
    "case_start = (df[df[\"status\"]==\"START\"]\n",
    "              .groupby([\"simulation_run\",\"case_id\"])[\"timestamp\"].min()\n",
    "              .rename(\"case_start\"))\n",
    "case_last  = df.groupby([\"simulation_run\",\"case_id\"])[\"timestamp\"].max().rename(\"case_last\")\n",
    "case_end   = (df[df[\"status\"]==\"COMPLETE\"]\n",
    "              .groupby([\"simulation_run\",\"case_id\"])[\"timestamp\"].max()\n",
    "              .rename(\"case_end\"))\n",
    "case_meta  = (pd.concat([case_start, case_end, case_last], axis=1)\n",
    "                .reset_index())\n",
    "case_meta[\"case_end_fallback\"] = case_meta[\"case_end\"].fillna(case_meta[\"case_last\"])\n",
    "\n",
    "# keep cases fully inside SS window for discovery & consistency\n",
    "global_tmax = df[\"timestamp\"].max()\n",
    "warmup_cut  = global_tmax * WARMUP_FRAC\n",
    "cool_cut    = global_tmax * (1-COOLDOWN_FRAC)\n",
    "keep_cases = case_meta[\n",
    "    (case_meta[\"case_start\"] >= warmup_cut) &\n",
    "    (case_meta[\"case_end_fallback\"] <= cool_cut)\n",
    "][[\"simulation_run\",\"case_id\"]]\n",
    "df_ss_cases = df.merge(keep_cases.assign(_keep=1), on=[\"simulation_run\",\"case_id\"], how=\"inner\")\n",
    "\n",
    "starts = (df_ss_cases[df_ss_cases[\"status\"]==\"START\"]\n",
    "          .groupby(\"simulation_run\")[\"case_id\"].nunique())\n",
    "completes = (df_ss_cases[df_ss_cases[\"status\"]==\"COMPLETE\"]\n",
    "             .groupby(\"simulation_run\")[\"case_id\"].nunique())\n",
    "starts_vs_completes = pd.concat([starts.rename(\"n_start\"), completes.rename(\"n_complete\")], axis=1).fillna(0).astype(int)\n",
    "starts_vs_completes[\"match\"] = starts_vs_completes[\"n_start\"] == starts_vs_completes[\"n_complete\"]\n",
    "print(starts_vs_completes)\n",
    "print(\"All runs balanced:\", starts_vs_completes[\"match\"].all())\n",
    "\n",
    "# cycle time consistency on COMPLETE rows\n",
    "comp = df_ss_cases[df_ss_cases[\"status\"]==\"COMPLETE\"].copy()\n",
    "comp = comp.merge(case_start.rename(\"case_start_time\").reset_index(),\n",
    "                  on=[\"simulation_run\",\"case_id\"], how=\"left\")\n",
    "comp[\"ct_recalc\"] = comp[\"timestamp\"] - comp[\"case_start_time\"]\n",
    "if \"cycle_time\" in comp.columns:\n",
    "    comp[\"cycle_time\"] = pd.to_numeric(comp[\"cycle_time\"], errors=\"coerce\")\n",
    "    comp[\"ct_diff\"] = (comp[\"ct_recalc\"] - comp[\"cycle_time\"]).abs()\n",
    "    print(\"Cycle-time max abs diff:\", (comp[\"ct_diff\"].max() if not comp.empty else 0.0))\n",
    "else:\n",
    "    print(\"No 'cycle_time' column found; skipped direct comparison.\")\n",
    "\n",
    "# ---------- Optional: save discovery-ready log ----------\n",
    "if SAVE_DISCOVERY:\n",
    "    os.makedirs(os.path.dirname(DISCOVERY_OUT), exist_ok=True)\n",
    "    df_ss_cases.to_csv(DISCOVERY_OUT, index=False)\n",
    "    print(f\"\\nSaved discovery dataset: {DISCOVERY_OUT}  \"\n",
    "          f\"(cases: {df_ss_cases['case_id'].nunique()}, events: {len(df_ss_cases)})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3c95231d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num task instances: 72378\n",
      "sample inst:\n",
      "    simulation_run run_case    activity  queued_ts   start_ts     end_ts  \\\n",
      "0               0      0_0  ASSEMBLY_1  20.393651  20.393651  24.866156   \n",
      "1               0      0_0  ASSEMBLY_2  24.866156  24.866156  26.676780   \n",
      "2               0      0_0    MOULDING  18.537263  18.537263  20.393651   \n",
      "3               0      0_0   PACKAGING  29.063644  29.063644  36.031979   \n",
      "4               0      0_0     SORTING  26.676780  26.676780  29.063644   \n",
      "\n",
      "        resource_name  \n",
      "0    LINE_1_ASSEMBLY1  \n",
      "1    ASSEMBLY2_LINE_1  \n",
      "2  MOULDING_MACHINE_1  \n",
      "3    PACKAGING_LINE_1  \n",
      "4       SORTING_ROBOT  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 113\u001b[39m\n\u001b[32m    110\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mEND\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    111\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m np.nan\n\u001b[32m--> \u001b[39m\u001b[32m113\u001b[39m gates[\u001b[33m\"\u001b[39m\u001b[33mnext_activity\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[43m[\u001b[49m\n\u001b[32m    114\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnext_step_after_gateway\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    115\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgates\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_case\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrow_in_case\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitertuples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    116\u001b[39m \u001b[43m]\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;66;03m# Empirical routing per gateway label (aggregated across all runs)\u001b[39;00m\n\u001b[32m    119\u001b[39m routing_emp = (\n\u001b[32m    120\u001b[39m     gates.groupby(\u001b[33m\"\u001b[39m\u001b[33mactivity\u001b[39m\u001b[33m\"\u001b[39m)[\u001b[33m\"\u001b[39m\u001b[33mnext_activity\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    121\u001b[39m          .value_counts(normalize=\u001b[38;5;28;01mTrue\u001b[39;00m, dropna=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    122\u001b[39m          .rename(\u001b[33m\"\u001b[39m\u001b[33mprob\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    123\u001b[39m          .reset_index()\n\u001b[32m    124\u001b[39m )\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 114\u001b[39m, in \u001b[36m<listcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m    110\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mEND\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    111\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m np.nan\n\u001b[32m    113\u001b[39m gates[\u001b[33m\"\u001b[39m\u001b[33mnext_activity\u001b[39m\u001b[33m\"\u001b[39m] = [\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m     \u001b[43mnext_step_after_gateway\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m rc, r \u001b[38;5;129;01min\u001b[39;00m gates[[\u001b[33m\"\u001b[39m\u001b[33mrun_case\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33mrow_in_case\u001b[39m\u001b[33m\"\u001b[39m]].itertuples(index=\u001b[38;5;28;01mFalse\u001b[39;00m, name=\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    116\u001b[39m ]\n\u001b[32m    118\u001b[39m \u001b[38;5;66;03m# Empirical routing per gateway label (aggregated across all runs)\u001b[39;00m\n\u001b[32m    119\u001b[39m routing_emp = (\n\u001b[32m    120\u001b[39m     gates.groupby(\u001b[33m\"\u001b[39m\u001b[33mactivity\u001b[39m\u001b[33m\"\u001b[39m)[\u001b[33m\"\u001b[39m\u001b[33mnext_activity\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    121\u001b[39m          .value_counts(normalize=\u001b[38;5;28;01mTrue\u001b[39;00m, dropna=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    122\u001b[39m          .rename(\u001b[33m\"\u001b[39m\u001b[33mprob\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    123\u001b[39m          .reset_index()\n\u001b[32m    124\u001b[39m )\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 101\u001b[39m, in \u001b[36mnext_step_after_gateway\u001b[39m\u001b[34m(run_case, row_idx_after)\u001b[39m\n\u001b[32m     94\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mnext_step_after_gateway\u001b[39m(run_case, row_idx_after):\n\u001b[32m     95\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     96\u001b[39m \u001b[33;03m    Return the 'next activity' chosen after a gateway for a given run_case, by scanning\u001b[39;00m\n\u001b[32m     97\u001b[39m \u001b[33;03m    the subsequent rows (in order) for that case:\u001b[39;00m\n\u001b[32m     98\u001b[39m \u001b[33;03m      - first 'queued' row -> its activity is the chosen branch\u001b[39;00m\n\u001b[32m     99\u001b[39m \u001b[33;03m      - if none and gateway was QC_AFTER_PACKAGING, treat next COMPLETE as END\u001b[39;00m\n\u001b[32m    100\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m101\u001b[39m     sub = df_sorted[(df_sorted[\u001b[33m\"\u001b[39m\u001b[33mrun_case\u001b[39m\u001b[33m\"\u001b[39m] == run_case) & (\u001b[43mdf_sorted\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrow_in_case\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m>\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow_idx_after\u001b[49m)]\n\u001b[32m    102\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m sub.empty:\n\u001b[32m    103\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m np.nan\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\990215322\\Desktop\\MuProMAC\\.venv\\Lib\\site-packages\\pandas\\core\\ops\\common.py:76\u001b[39m, in \u001b[36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[39m\u001b[34m(self, other)\u001b[39m\n\u001b[32m     72\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[32m     74\u001b[39m other = item_from_zerodim(other)\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\990215322\\Desktop\\MuProMAC\\.venv\\Lib\\site-packages\\pandas\\core\\arraylike.py:56\u001b[39m, in \u001b[36mOpsMixin.__gt__\u001b[39m\u001b[34m(self, other)\u001b[39m\n\u001b[32m     54\u001b[39m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m__gt__\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__gt__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[32m---> \u001b[39m\u001b[32m56\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_cmp_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgt\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\990215322\\Desktop\\MuProMAC\\.venv\\Lib\\site-packages\\pandas\\core\\series.py:6138\u001b[39m, in \u001b[36mSeries._cmp_method\u001b[39m\u001b[34m(self, other, op)\u001b[39m\n\u001b[32m   6135\u001b[39m lvalues = \u001b[38;5;28mself\u001b[39m._values\n\u001b[32m   6136\u001b[39m rvalues = extract_array(other, extract_numpy=\u001b[38;5;28;01mTrue\u001b[39;00m, extract_range=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m6138\u001b[39m res_values = \u001b[43mops\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcomparison_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6140\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._construct_result(res_values, name=res_name)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\990215322\\Desktop\\MuProMAC\\.venv\\Lib\\site-packages\\pandas\\core\\ops\\array_ops.py:347\u001b[39m, in \u001b[36mcomparison_op\u001b[39m\u001b[34m(left, right, op)\u001b[39m\n\u001b[32m    344\u001b[39m     res_values = comp_method_OBJECT_ARRAY(op, lvalues, rvalues)\n\u001b[32m    346\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m347\u001b[39m     res_values = \u001b[43m_na_arithmetic_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_cmp\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    349\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m res_values\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\990215322\\Desktop\\MuProMAC\\.venv\\Lib\\site-packages\\pandas\\core\\ops\\array_ops.py:218\u001b[39m, in \u001b[36m_na_arithmetic_op\u001b[39m\u001b[34m(left, right, op, is_cmp)\u001b[39m\n\u001b[32m    215\u001b[39m     func = partial(expressions.evaluate, op)\n\u001b[32m    217\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m    220\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_cmp \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[32m    221\u001b[39m         left.dtype == \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(right, \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) == \u001b[38;5;28mobject\u001b[39m\n\u001b[32m    222\u001b[39m     ):\n\u001b[32m   (...)\u001b[39m\u001b[32m    225\u001b[39m         \u001b[38;5;66;03m# Don't do this for comparisons, as that will handle complex numbers\u001b[39;00m\n\u001b[32m    226\u001b[39m         \u001b[38;5;66;03m#  incorrectly, see GH#32047\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\990215322\\Desktop\\MuProMAC\\.venv\\Lib\\site-packages\\pandas\\core\\computation\\expressions.py:242\u001b[39m, in \u001b[36mevaluate\u001b[39m\u001b[34m(op, a, b, use_numexpr)\u001b[39m\n\u001b[32m    239\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m op_str \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    240\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m use_numexpr:\n\u001b[32m    241\u001b[39m         \u001b[38;5;66;03m# error: \"None\" not callable\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m242\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m    243\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _evaluate_standard(op, op_str, a, b)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\990215322\\Desktop\\MuProMAC\\.venv\\Lib\\site-packages\\pandas\\core\\computation\\expressions.py:73\u001b[39m, in \u001b[36m_evaluate_standard\u001b[39m\u001b[34m(op, op_str, a, b)\u001b[39m\n\u001b[32m     71\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _TEST_MODE:\n\u001b[32m     72\u001b[39m     _store_test_result(\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m op(a, b)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- Load ---\n",
    "df = pd.read_csv(\"results/251020FIFO_l0.28_actuator_manufacturing_with_rework.csv\")\n",
    "\n",
    "# Keep only relevant cols\n",
    "cols = [\"simulation_run\",\"timestamp\",\"status\",\"case_id\",\"activity\",\"resource\",\"end_time\",\"cycle_time\",\"data\",\"scenario\",\"l\",\"method\"]\n",
    "df = df[cols].copy()\n",
    "\n",
    "# Parse numeric\n",
    "df[\"timestamp\"] = pd.to_numeric(df[\"timestamp\"], errors=\"coerce\")\n",
    "df[\"end_time\"] = pd.to_numeric(df[\"end_time\"], errors=\"coerce\")\n",
    "\n",
    "# === CRITICAL: Create composite case identifier ===\n",
    "df[\"run_case\"] = df[\"simulation_run\"].astype(str) + \"_\" + df[\"case_id\"].astype(str)\n",
    "\n",
    "# --- 1) basic schema sanity ---\n",
    "required = [\"timestamp\",\"status\",\"case_id\",\"activity\"]\n",
    "missing_cols = [c for c in required if c not in df.columns]\n",
    "assert not missing_cols, f\"Missing columns: {missing_cols}\"\n",
    "assert df[required].isnull().sum().sum() == 0, \"Nulls found in required fields\"\n",
    "\n",
    "# --- 2) reconstruct task instances (robust pairing) ---\n",
    "# Keep only task lifecycle rows (exclude gateways and START/COMPLETE for case)\n",
    "task_rows = df[df[\"activity\"].ne(\"START\") & df[\"status\"].isin([\"queued\",\"running\"])].copy()\n",
    "\n",
    "# Sort so cumcounts respect time\n",
    "task_rows = task_rows.sort_values([\"run_case\",\"activity\",\"timestamp\"]).copy()\n",
    "\n",
    "# Split and make occurrence indices *per status* (not mixed)\n",
    "queued = task_rows[task_rows[\"status\"]==\"queued\"].copy()\n",
    "queued[\"occ_q\"] = queued.groupby([\"run_case\",\"activity\"]).cumcount()\n",
    "\n",
    "running = task_rows[task_rows[\"status\"]==\"running\"].copy()\n",
    "running[\"occ_r\"] = running.groupby([\"run_case\",\"activity\"]).cumcount()\n",
    "\n",
    "# Merge kth queued with kth running for each (run_case, activity)\n",
    "inst = pd.merge(\n",
    "    queued[[\"simulation_run\",\"run_case\",\"activity\",\"occ_q\",\"timestamp\"]].rename(columns={\"timestamp\":\"queued_ts\"}),\n",
    "    running[[\"run_case\",\"activity\",\"occ_r\",\"timestamp\",\"end_time\",\"resource\"]].rename(\n",
    "        columns={\"timestamp\":\"start_ts\",\"end_time\":\"end_ts\",\"resource\":\"resource_name\"}),\n",
    "    left_on=[\"run_case\",\"activity\",\"occ_q\"],\n",
    "    right_on=[\"run_case\",\"activity\",\"occ_r\"],\n",
    "    how=\"inner\",\n",
    ").drop(columns=[\"occ_q\",\"occ_r\"])\n",
    "\n",
    "print(\"num task instances:\", len(inst))\n",
    "print(\"sample inst:\\n\", inst.head())\n",
    "\n",
    "# Durations\n",
    "inst[\"wait\"] = inst[\"start_ts\"] - inst[\"queued_ts\"]\n",
    "inst[\"service\"] = inst[\"end_ts\"] - inst[\"start_ts\"]\n",
    "inst[\"sojourn\"] = inst[\"end_ts\"] - inst[\"queued_ts\"]\n",
    "\n",
    "# Sanity: no negatives\n",
    "neg = inst[(inst[\"wait\"]<0) | (inst[\"service\"]<0) | (inst[\"sojourn\"]<0)]\n",
    "assert neg.empty, f\"Negative times found:\\n{neg.head()}\"\n",
    "\n",
    "\n",
    "# --- 3) FIFO discipline per station (warning-free) ---\n",
    "# Check FIFO within each run separately\n",
    "tmp = inst.sort_values([\"simulation_run\",\"activity\",\"queued_ts\",\"start_ts\"]).copy()\n",
    "eps = 1e-9\n",
    "tmp[\"dec\"] = tmp.groupby([\"simulation_run\",\"activity\"])[\"start_ts\"].diff() < -eps\n",
    "\n",
    "fifo_check = (\n",
    "    tmp.groupby([\"simulation_run\",\"activity\"], as_index=False)\n",
    "       .agg(num_instances=(\"start_ts\",\"size\"),\n",
    "            fifo_violations=(\"dec\",\"sum\"))\n",
    ")\n",
    "fifo_check[\"fifo_violations\"] = fifo_check[\"fifo_violations\"].astype(int)\n",
    "\n",
    "# Aggregate across runs\n",
    "fifo_summary = (\n",
    "    fifo_check.groupby(\"activity\", as_index=False)\n",
    "    .agg(\n",
    "        total_instances=(\"num_instances\",\"sum\"),\n",
    "        total_violations=(\"fifo_violations\",\"sum\"),\n",
    "        runs_with_violations=(\"fifo_violations\", lambda x: (x > 0).sum())\n",
    "    )\n",
    ")\n",
    "\n",
    "# --- 4) routing/QC probabilities (position-based, handles same-timestamp + END) ---\n",
    "\n",
    "# Sort by run_case then time, and give each row an order within the run_case\n",
    "df_sorted = df.sort_values([\"run_case\", \"timestamp\"]).copy()\n",
    "df_sorted[\"row_in_case\"] = df_sorted.groupby(\"run_case\").cumcount()\n",
    "\n",
    "# Grab gateway rows (after they have row_in_case)\n",
    "gates = df_sorted[df_sorted[\"status\"] == \"gateway\"][[\"simulation_run\",\"run_case\",\"timestamp\",\"activity\",\"row_in_case\"]].copy()\n",
    "gates = gates.sort_values([\"run_case\",\"row_in_case\"]).reset_index(drop=True)\n",
    "\n",
    "def next_step_after_gateway(run_case, row_idx_after):\n",
    "    \"\"\"\n",
    "    Return the 'next activity' chosen after a gateway for a given run_case, by scanning\n",
    "    the subsequent rows (in order) for that case:\n",
    "      - first 'queued' row -> its activity is the chosen branch\n",
    "      - if none and gateway was QC_AFTER_PACKAGING, treat next COMPLETE as END\n",
    "    \"\"\"\n",
    "    sub = df_sorted[(df_sorted[\"run_case\"] == run_case) & (df_sorted[\"row_in_case\"] > row_idx_after)]\n",
    "    if sub.empty:\n",
    "        return np.nan\n",
    "    nxt_q = sub.loc[sub[\"status\"] == \"queued\"]\n",
    "    if not nxt_q.empty:\n",
    "        return nxt_q.iloc[0][\"activity\"]\n",
    "    # No queued afterwards; for packaging gateway the case may complete next\n",
    "    nxt_c = sub.loc[sub[\"status\"] == \"COMPLETE\"]\n",
    "    if not nxt_c.empty:\n",
    "        return \"END\"\n",
    "    return np.nan\n",
    "\n",
    "gates[\"next_activity\"] = [\n",
    "    next_step_after_gateway(rc, r)\n",
    "    for rc, r in gates[[\"run_case\",\"row_in_case\"]].itertuples(index=False, name=None)\n",
    "]\n",
    "\n",
    "# Empirical routing per gateway label (aggregated across all runs)\n",
    "routing_emp = (\n",
    "    gates.groupby(\"activity\")[\"next_activity\"]\n",
    "         .value_counts(normalize=True, dropna=True)\n",
    "         .rename(\"prob\")\n",
    "         .reset_index()\n",
    ")\n",
    "\n",
    "# Expected (from your config)\n",
    "expected = {\n",
    "    \"QC_AFTER_MOULDING\":  {\"MOULDING\": 0.05, \"ASSEMBLY_1\": 0.95},\n",
    "    \"QC_AFTER_ASSEMBLY1\": {\"ASSEMBLY_1\": 0.05, \"ASSEMBLY_2\": 0.95},\n",
    "    \"QC_AFTER_ASSEMBLY2\": {\"ASSEMBLY_2\": 0.05, \"SORTING\":    0.95},\n",
    "    \"QC_AFTER_SORTING\":   {\"SORTING\":   0.05, \"PACKAGING\":   0.95},\n",
    "    \"QC_AFTER_PACKAGING\": {\"PACKAGING\": 0.05, \"END\":         0.95},\n",
    "}\n",
    "routing_exp = pd.DataFrame(\n",
    "    [{\"activity\": g, \"next_activity\": nxt, \"expected\": p}\n",
    "     for g, dd in expected.items() for nxt, p in dd.items()]\n",
    ")\n",
    "\n",
    "routing = (routing_exp\n",
    "           .merge(routing_emp, on=[\"activity\",\"next_activity\"], how=\"left\")\n",
    "           .fillna({\"prob\": 0.0}))\n",
    "routing[\"diff\"] = routing[\"prob\"] - routing[\"expected\"]\n",
    "\n",
    "print(\"\\nRouting empirical vs expected (aggregated across all runs):\")\n",
    "print(routing.sort_values([\"activity\",\"next_activity\"]))\n",
    "\n",
    "# How many gateways had 0-wait to the next station?\n",
    "merge_for_wait = gates.merge(\n",
    "    inst[[\"run_case\",\"activity\",\"queued_ts\",\"start_ts\"]],\n",
    "    left_on=[\"run_case\",\"next_activity\"], right_on=[\"run_case\",\"activity\"],\n",
    "    how=\"left\", suffixes=(\"_gate\",\"_next\")\n",
    ")\n",
    "zero_wait_share = (merge_for_wait[\"start_ts\"] - merge_for_wait[\"timestamp\"] <= 1e-9).mean()\n",
    "print(\"Share of gateways with immediate (zero-wait) handoff:\", zero_wait_share)\n",
    "\n",
    "\n",
    "# --- 5) service-time by resource (aggregated across runs) ---\n",
    "svc = inst.dropna(subset=[\"resource_name\",\"service\"]).copy()\n",
    "svc_stats = svc.groupby(\"resource_name\")[\"service\"].agg([\"count\",\"mean\",\"std\",\"min\",\"max\"]).reset_index()\n",
    "\n",
    "# Rough exponential check: for Exp, mean ≈ std; ratio near 1 is indicative (not proof)\n",
    "svc_stats[\"std_over_mean\"] = svc_stats[\"std\"]/svc_stats[\"mean\"]\n",
    "\n",
    "# --- 6) utilization & throughput (per run, then averaged) ---\n",
    "# Calculate per run first\n",
    "util_per_run = []\n",
    "for run_id in df[\"simulation_run\"].unique():\n",
    "    df_run = df[df[\"simulation_run\"] == run_id]\n",
    "    inst_run = inst[inst[\"simulation_run\"] == run_id]\n",
    "    \n",
    "    T = df_run[\"timestamp\"].max()\n",
    "    busy = (\n",
    "        inst_run.groupby(\"resource_name\", as_index=False)[\"service\"]\n",
    "           .sum()\n",
    "           .rename(columns={\"service\":\"busy_time\"})\n",
    "    )\n",
    "    busy[\"utilization\"] = busy[\"busy_time\"] / T\n",
    "    busy[\"simulation_run\"] = run_id\n",
    "    util_per_run.append(busy)\n",
    "\n",
    "# Average utilization across runs\n",
    "util_all = pd.concat(util_per_run, ignore_index=True)\n",
    "util_summary = (\n",
    "    util_all.groupby(\"resource_name\")[\"utilization\"]\n",
    "    .agg([\"mean\",\"std\",\"min\",\"max\"])\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Station-level KPIs (aggregated across runs)\n",
    "station = inst.groupby(\"activity\").agg(\n",
    "    arrivals=(\"activity\",\"size\"),\n",
    "    mean_wait=(\"wait\",\"mean\"),\n",
    "    mean_service=(\"service\",\"mean\"),\n",
    "    mean_sojourn=(\"sojourn\",\"mean\")\n",
    ").reset_index()\n",
    "\n",
    "# --- 7) Little's Law check: aggregate across runs ---\n",
    "# Use total simulation time across all runs\n",
    "total_sim_time = df.groupby(\"simulation_run\")[\"timestamp\"].max().sum()\n",
    "station[\"lambda\"] = station[\"arrivals\"] / total_sim_time\n",
    "station[\"L_hat\"] = station[\"lambda\"] * station[\"mean_sojourn\"]\n",
    "\n",
    "# --- Summaries to print or save ---\n",
    "print(\"\\nFIFO violations summary (should be 0):\")\n",
    "print(fifo_summary.sort_values(\"total_violations\", ascending=False))\n",
    "\n",
    "print(\"\\nService by resource (std/mean ~ 1 for Exp):\")\n",
    "print(svc_stats.sort_values(\"std_over_mean\"))\n",
    "\n",
    "print(\"\\nResource utilization (mean across runs):\")\n",
    "print(util_summary.sort_values(\"mean\", ascending=False).head(10))\n",
    "\n",
    "print(\"\\nStation KPIs + Little's Law proxy:\")\n",
    "print(station.sort_values(\"L_hat\", ascending=False).head(10))\n",
    "\n",
    "# --- Stability audit: capacity vs offered load, with warm-up trim ---\n",
    "# Do this per run, then average\n",
    "stab_per_run = []\n",
    "\n",
    "for run_id in df[\"simulation_run\"].unique():\n",
    "    df_run = df[df[\"simulation_run\"] == run_id]\n",
    "    inst_run = inst[inst[\"simulation_run\"] == run_id]\n",
    "    \n",
    "    warmup = df_run[\"timestamp\"].max() * 0.05\n",
    "    inst_ss = inst_run[inst_run[\"queued_ts\"] >= warmup].copy()\n",
    "    \n",
    "    T_eff = df_run[\"timestamp\"].max() - warmup\n",
    "    arrivals_run = inst_ss.groupby(\"activity\")[\"activity\"].size().rename(\"arrivals\").reset_index()\n",
    "    arrivals_run[\"lambda_station\"] = arrivals_run[\"arrivals\"] / T_eff\n",
    "    \n",
    "    svc_ss = inst_ss.dropna(subset=[\"resource_name\",\"service\"]).copy()\n",
    "    rs = (svc_ss.groupby([\"activity\",\"resource_name\"])[\"service\"]\n",
    "                .mean()\n",
    "                .rename(\"mean_service\")\n",
    "                .reset_index())\n",
    "    \n",
    "    cap = (rs.assign(mu=lambda d: 1.0 / d[\"mean_service\"])\n",
    "             .groupby(\"activity\")[\"mu\"].sum()\n",
    "             .rename(\"capacity\")\n",
    "             .reset_index())\n",
    "    \n",
    "    stab_run = arrivals_run.merge(cap, on=\"activity\", how=\"left\")\n",
    "    stab_run[\"rho_hat\"] = stab_run[\"lambda_station\"] / stab_run[\"capacity\"]\n",
    "    stab_run[\"headroom\"] = 1.0 - stab_run[\"rho_hat\"]\n",
    "    stab_run[\"simulation_run\"] = run_id\n",
    "    \n",
    "    stab_per_run.append(stab_run)\n",
    "\n",
    "# Average stability metrics across runs\n",
    "stab_all = pd.concat(stab_per_run, ignore_index=True)\n",
    "stab_summary = (\n",
    "    stab_all.groupby(\"activity\")\n",
    "    .agg(\n",
    "        mean_rho=(\"rho_hat\",\"mean\"),\n",
    "        std_rho=(\"rho_hat\",\"std\"),\n",
    "        mean_headroom=(\"headroom\",\"mean\"),\n",
    "        min_headroom=(\"headroom\",\"min\")\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "print(\"\\nStability headroom by station (mean across runs; ρ < 1 required; aim for headroom ≥ 0.05):\")\n",
    "print(stab_summary.sort_values(\"mean_rho\", ascending=False))\n",
    "\n",
    "# --- Queue end-trend analysis (per run, then summarize) ---\n",
    "def queue_trace(inst_df, act):\n",
    "    g = inst_df[inst_df[\"activity\"]==act][[\"queued_ts\",\"start_ts\"]].copy()\n",
    "    if g.empty: \n",
    "        return None\n",
    "    ups   = g.groupby(\"queued_ts\").size().rename(\"delta\")\n",
    "    downs = (g.groupby(\"start_ts\").size() * -1).rename(\"delta\")\n",
    "    deltas = pd.concat([ups, downs], axis=0).groupby(level=0).sum().sort_index()\n",
    "    tr = deltas.cumsum().reset_index().rename(columns={\"index\":\"time\",\"delta\":\"qlen\"})\n",
    "    tr[\"qlen\"] = tr[\"qlen\"].clip(lower=0)\n",
    "    return tr\n",
    "\n",
    "def end_trend_slope(trace, tail_frac=0.2):\n",
    "    if trace is None or len(trace) < 5: \n",
    "        return np.nan\n",
    "    n0 = int(len(trace)*(1-tail_frac))\n",
    "    tail = trace.iloc[max(n0,0):].copy()\n",
    "    if len(tail) < 3: \n",
    "        return np.nan\n",
    "    x = tail[\"time\"].values\n",
    "    y = tail[\"qlen\"].values\n",
    "    A = np.vstack([x, np.ones_like(x)]).T\n",
    "    slope, _ = np.linalg.lstsq(A, y, rcond=None)[0]\n",
    "    return slope\n",
    "\n",
    "trend_per_run = []\n",
    "for run_id in df[\"simulation_run\"].unique():\n",
    "    inst_run = inst[inst[\"simulation_run\"] == run_id]\n",
    "    warmup = df[df[\"simulation_run\"] == run_id][\"timestamp\"].max() * 0.05\n",
    "    inst_ss = inst_run[inst_run[\"queued_ts\"] >= warmup]\n",
    "    \n",
    "    acts = sorted(inst_ss[\"activity\"].unique())\n",
    "    for act in acts:\n",
    "        tr = queue_trace(inst_ss, act)\n",
    "        slope = end_trend_slope(tr, tail_frac=0.3)\n",
    "        trend_per_run.append({\n",
    "            \"simulation_run\": run_id,\n",
    "            \"activity\": act, \n",
    "            \"end_slope_q_per_min\": slope\n",
    "        })\n",
    "\n",
    "trend_df = pd.DataFrame(trend_per_run)\n",
    "trend_summary = (\n",
    "    trend_df.groupby(\"activity\")[\"end_slope_q_per_min\"]\n",
    "    .agg([\"mean\",\"std\",\"min\",\"max\"])\n",
    "    .reset_index()\n",
    "    .sort_values(\"mean\", ascending=False)\n",
    ")\n",
    "\n",
    "print(\"\\nQueue end-trend slope (mean across runs; ≈0 is good; persistently >0 indicates growing backlog):\")\n",
    "print(trend_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "44d1001d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num task instances: 72378\n",
      "sample inst:\n",
      "    simulation_run  case_id    activity  queued_ts   start_ts     end_ts  \\\n",
      "0               0        0  ASSEMBLY_1  20.393651  20.393651  24.866156   \n",
      "1               0        0  ASSEMBLY_2  24.866156  24.866156  26.676780   \n",
      "2               0        0    MOULDING  18.537263  18.537263  20.393651   \n",
      "3               0        0   PACKAGING  29.063644  29.063644  36.031979   \n",
      "4               0        0     SORTING  26.676780  26.676780  29.063644   \n",
      "\n",
      "        resource_name  \n",
      "0    LINE_1_ASSEMBLY1  \n",
      "1    ASSEMBLY2_LINE_1  \n",
      "2  MOULDING_MACHINE_1  \n",
      "3    PACKAGING_LINE_1  \n",
      "4       SORTING_ROBOT  \n",
      "\n",
      "Routing empirical vs expected (position-based):\n",
      "             activity next_activity  expected      prob      diff\n",
      "2  QC_AFTER_ASSEMBLY1    ASSEMBLY_1      0.05  0.050476  0.000476\n",
      "3  QC_AFTER_ASSEMBLY1    ASSEMBLY_2      0.95  0.949524 -0.000476\n",
      "4  QC_AFTER_ASSEMBLY2    ASSEMBLY_2      0.05  0.049473 -0.000527\n",
      "5  QC_AFTER_ASSEMBLY2       SORTING      0.95  0.950527  0.000527\n",
      "1   QC_AFTER_MOULDING    ASSEMBLY_1      0.95  0.946330 -0.003670\n",
      "0   QC_AFTER_MOULDING      MOULDING      0.05  0.053670  0.003670\n",
      "9  QC_AFTER_PACKAGING           END      0.95  0.947190 -0.002810\n",
      "8  QC_AFTER_PACKAGING     PACKAGING      0.05  0.052810  0.002810\n",
      "7    QC_AFTER_SORTING     PACKAGING      0.95  0.948533 -0.001467\n",
      "6    QC_AFTER_SORTING       SORTING      0.05  0.051467  0.001467\n",
      "Share of gateways with immediate (zero-wait) handoff: 0.4491345124944924\n",
      "\n",
      "FIFO violations per station per run (should be 0):\n",
      "activity\n",
      "ASSEMBLY_1    0\n",
      "ASSEMBLY_2    0\n",
      "MOULDING      0\n",
      "PACKAGING     0\n",
      "SORTING       0\n",
      "Name: fifo_violations, dtype: int64\n",
      "\n",
      "Routing empirical vs expected (diff near 0):\n",
      "             activity next_activity  expected      prob      diff\n",
      "2  QC_AFTER_ASSEMBLY1    ASSEMBLY_1      0.05  0.050476  0.000476\n",
      "3  QC_AFTER_ASSEMBLY1    ASSEMBLY_2      0.95  0.949524 -0.000476\n",
      "4  QC_AFTER_ASSEMBLY2    ASSEMBLY_2      0.05  0.049473 -0.000527\n",
      "5  QC_AFTER_ASSEMBLY2       SORTING      0.95  0.950527  0.000527\n",
      "1   QC_AFTER_MOULDING    ASSEMBLY_1      0.95  0.946330 -0.003670\n",
      "0   QC_AFTER_MOULDING      MOULDING      0.05  0.053670  0.003670\n",
      "9  QC_AFTER_PACKAGING           END      0.95  0.947190 -0.002810\n",
      "8  QC_AFTER_PACKAGING     PACKAGING      0.05  0.052810  0.002810\n",
      "7    QC_AFTER_SORTING     PACKAGING      0.95  0.948533 -0.001467\n",
      "6    QC_AFTER_SORTING       SORTING      0.05  0.051467  0.001467\n",
      "\n",
      "Service by resource (std/mean ~ 1 for Exp):\n",
      "         resource_name  count      mean       std       min        max  \\\n",
      "6     LINE_5_ASSEMBLY1   2871  7.083801  6.987336  0.002357  66.305483   \n",
      "10  MOULDING_MACHINE_4   2926  4.999226  4.950939  0.000116  48.648856   \n",
      "3     LINE_2_ASSEMBLY1   2929  6.967801  6.925688  0.005162  67.590373   \n",
      "4     LINE_3_ASSEMBLY1   2939  6.863156  6.841646  0.004411  53.582025   \n",
      "2     LINE_1_ASSEMBLY1   2860  7.157108  7.140363  0.000033  64.519338   \n",
      "13    PACKAGING_LINE_2   4811  4.037777  4.040354  0.003123  32.609819   \n",
      "14    PACKAGING_LINE_3   4777  4.047245  4.053756  0.000042  30.562674   \n",
      "7   MOULDING_MACHINE_1   2923  5.004153  5.016944  0.001167  34.871909   \n",
      "9   MOULDING_MACHINE_3   2914  5.023618  5.041928  0.000698  45.081951   \n",
      "11  MOULDING_MACHINE_5   2907  4.980900  5.007419  0.001029  46.187383   \n",
      "0     ASSEMBLY2_LINE_1   7175  6.055029  6.089215  0.000169  61.590113   \n",
      "15       SORTING_ROBOT  14424  2.978959  3.006982  0.000496  26.534880   \n",
      "5     LINE_4_ASSEMBLY1   2903  6.915785  6.991639  0.002630  62.860827   \n",
      "12    PACKAGING_LINE_1   4849  3.987160  4.047371  0.000724  29.263212   \n",
      "1     ASSEMBLY2_LINE_2   7273  5.963634  6.061831  0.000421  58.950226   \n",
      "8   MOULDING_MACHINE_2   2897  5.072953  5.213693  0.002061  45.871136   \n",
      "\n",
      "    std_over_mean  \n",
      "6        0.986382  \n",
      "10       0.990341  \n",
      "3        0.993956  \n",
      "4        0.996866  \n",
      "2        0.997660  \n",
      "13       1.000638  \n",
      "14       1.001609  \n",
      "7        1.002556  \n",
      "9        1.003645  \n",
      "11       1.005324  \n",
      "0        1.005646  \n",
      "15       1.009407  \n",
      "5        1.010968  \n",
      "12       1.015101  \n",
      "1        1.016466  \n",
      "8        1.027743  \n",
      "\n",
      "Resource utilization (sanity):\n",
      "       resource_name     busy_time  utilization\n",
      "0   ASSEMBLY2_LINE_1  43444.833113     0.868948\n",
      "1   ASSEMBLY2_LINE_2  43373.511683     0.867522\n",
      "15     SORTING_ROBOT  42968.503434     0.859421\n",
      "2   LINE_1_ASSEMBLY1  20469.329199     0.409411\n",
      "3   LINE_2_ASSEMBLY1  20408.688599     0.408198\n",
      "6   LINE_5_ASSEMBLY1  20337.593848     0.406776\n",
      "4   LINE_3_ASSEMBLY1  20170.815429     0.403440\n",
      "5   LINE_4_ASSEMBLY1  20076.524961     0.401554\n",
      "13  PACKAGING_LINE_2  19425.745278     0.388538\n",
      "12  PACKAGING_LINE_1  19333.736728     0.386698\n",
      "\n",
      "Station KPIs + Little's Law proxy:\n",
      "     activity  arrivals  mean_wait  mean_service  mean_sojourn    lambda  \\\n",
      "1  ASSEMBLY_2     14448  17.638605      6.009022     23.647626  0.288977   \n",
      "4     SORTING     14424  16.403159      2.978959     19.382118  0.288497   \n",
      "0  ASSEMBLY_1     14502   0.134694      6.996480      7.131174  0.290057   \n",
      "2    MOULDING     14567   0.024488      5.016099      5.040588  0.291357   \n",
      "3   PACKAGING     14437   0.311085      4.023909      4.334994  0.288757   \n",
      "\n",
      "      L_hat  \n",
      "1  6.833625  \n",
      "4  5.591686  \n",
      "0  2.068449  \n",
      "2  1.468612  \n",
      "3  1.251761  \n",
      "\n",
      "Average stability headroom by station across all runs:\n",
      "     activity   rho_hat  headroom  lambda_station  capacity\n",
      "1  ASSEMBLY_2  0.871589  0.128411        0.289765  0.332657\n",
      "4     SORTING  0.863872  0.136128        0.289975  0.335918\n",
      "0  ASSEMBLY_1  0.405702  0.594298        0.289954  0.714982\n",
      "3   PACKAGING  0.391061  0.608939        0.291428  0.745747\n",
      "2    MOULDING  0.291746  0.708254        0.291238  0.998647\n",
      "\n",
      "Average queue end-trend slope across all runs (jobs/min; ≈0 is good):\n",
      "     activity  end_slope_q_per_min\n",
      "2    MOULDING            -0.000001\n",
      "3   PACKAGING            -0.000030\n",
      "0  ASSEMBLY_1            -0.000056\n",
      "4     SORTING            -0.001740\n",
      "1  ASSEMBLY_2            -0.001955\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- Load ---\n",
    "df = pd.read_csv(\"results/251020FIFO_l0.28_actuator_manufacturing_with_rework.csv\")\n",
    "\n",
    "# Keep only relevant cols\n",
    "cols = [\"simulation_run\",\"timestamp\",\"status\",\"case_id\",\"activity\",\"resource\",\"end_time\",\"cycle_time\",\"data\",\"scenario\",\"l\",\"method\"]\n",
    "df = df[cols].copy()\n",
    "\n",
    "# Parse numeric\n",
    "df[\"timestamp\"] = pd.to_numeric(df[\"timestamp\"], errors=\"coerce\")\n",
    "df[\"end_time\"] = pd.to_numeric(df[\"end_time\"], errors=\"coerce\")\n",
    "\n",
    "# --- 1) basic schema sanity ---\n",
    "required = [\"simulation_run\",\"timestamp\",\"status\",\"case_id\",\"activity\"]\n",
    "missing_cols = [c for c in required if c not in df.columns]\n",
    "assert not missing_cols, f\"Missing columns: {missing_cols}\"\n",
    "assert df[required].isnull().sum().sum() == 0, \"Nulls found in required fields\"\n",
    "\n",
    "# --- 2) reconstruct task instances (robust pairing) ---\n",
    "# Keep only task lifecycle rows (exclude gateways and START/COMPLETE for case)\n",
    "task_rows = df[df[\"activity\"].ne(\"START\") & df[\"status\"].isin([\"queued\",\"running\"])].copy()\n",
    "\n",
    "# Sort so cumcounts respect time\n",
    "task_rows = task_rows.sort_values([\"simulation_run\",\"case_id\",\"activity\",\"timestamp\"]).copy()\n",
    "\n",
    "# Split and make occurrence indices *per status* (not mixed)\n",
    "queued = task_rows[task_rows[\"status\"]==\"queued\"].copy()\n",
    "queued[\"occ_q\"] = queued.groupby([\"simulation_run\",\"case_id\",\"activity\"]).cumcount()\n",
    "\n",
    "running = task_rows[task_rows[\"status\"]==\"running\"].copy()\n",
    "running[\"occ_r\"] = running.groupby([\"simulation_run\",\"case_id\",\"activity\"]).cumcount()\n",
    "\n",
    "# Merge kth queued with kth running for each (simulation_run, case, activity)\n",
    "inst = pd.merge(\n",
    "    queued[[\"simulation_run\",\"case_id\",\"activity\",\"occ_q\",\"timestamp\"]].rename(columns={\"timestamp\":\"queued_ts\"}),\n",
    "    running[[\"simulation_run\",\"case_id\",\"activity\",\"occ_r\",\"timestamp\",\"end_time\",\"resource\"]].rename(\n",
    "        columns={\"timestamp\":\"start_ts\",\"end_time\":\"end_ts\",\"resource\":\"resource_name\"}),\n",
    "    left_on=[\"simulation_run\",\"case_id\",\"activity\",\"occ_q\"],\n",
    "    right_on=[\"simulation_run\",\"case_id\",\"activity\",\"occ_r\"],\n",
    "    how=\"inner\",\n",
    ").drop(columns=[\"occ_q\",\"occ_r\"])\n",
    "\n",
    "print(\"num task instances:\", len(inst))\n",
    "print(\"sample inst:\\n\", inst.head())\n",
    "\n",
    "# Durations\n",
    "inst[\"wait\"] = inst[\"start_ts\"] - inst[\"queued_ts\"]\n",
    "inst[\"service\"] = inst[\"end_ts\"] - inst[\"start_ts\"]\n",
    "inst[\"sojourn\"] = inst[\"end_ts\"] - inst[\"queued_ts\"]\n",
    "\n",
    "# Sanity: no negatives\n",
    "neg = inst[(inst[\"wait\"]<0) | (inst[\"service\"]<0) | (inst[\"sojourn\"]<0)]\n",
    "assert neg.empty, f\"Negative times found:\\n{neg.head()}\"\n",
    "\n",
    "# --- 3) FIFO discipline per station (warning-free) ---\n",
    "tmp = inst.sort_values([\"simulation_run\",\"activity\",\"queued_ts\",\"start_ts\"]).copy()\n",
    "eps = 1e-9\n",
    "tmp[\"dec\"] = tmp.groupby([\"simulation_run\",\"activity\"])[\"start_ts\"].diff() < -eps\n",
    "\n",
    "fifo_check = (\n",
    "    tmp.groupby([\"simulation_run\",\"activity\"], as_index=False)\n",
    "       .agg(num_instances=(\"start_ts\",\"size\"),\n",
    "            fifo_violations=(\"dec\",\"sum\"))\n",
    ")\n",
    "fifo_check[\"fifo_violations\"] = fifo_check[\"fifo_violations\"].astype(int)\n",
    "\n",
    "# --- 4) routing/QC probabilities (position-based, handles same-timestamp + END) ---\n",
    "\n",
    "# Sort by simulation_run, case then time, and give each row an order within the case\n",
    "df_sorted = df.sort_values([\"simulation_run\",\"case_id\", \"timestamp\"]).copy()\n",
    "df_sorted[\"row_in_case\"] = df_sorted.groupby([\"simulation_run\",\"case_id\"]).cumcount()\n",
    "\n",
    "# Grab gateway rows (after they have row_in_case)\n",
    "gates = df_sorted[df_sorted[\"status\"] == \"gateway\"][[\"simulation_run\",\"case_id\",\"timestamp\",\"activity\",\"row_in_case\"]].copy()\n",
    "gates = gates.sort_values([\"simulation_run\",\"case_id\",\"row_in_case\"]).reset_index(drop=True)\n",
    "\n",
    "def next_step_after_gateway(sim_run, case_id, row_idx_after):\n",
    "    \"\"\"\n",
    "    Return the 'next activity' chosen after a gateway for a given case, by scanning\n",
    "    the subsequent rows (in order) for that case:\n",
    "      - first 'queued' row -> its activity is the chosen branch\n",
    "      - if none and gateway was QC_AFTER_PACKAGING, treat next COMPLETE as END\n",
    "    \"\"\"\n",
    "    sub = df_sorted[(df_sorted[\"simulation_run\"] == sim_run) & \n",
    "                    (df_sorted[\"case_id\"] == case_id) & \n",
    "                    (df_sorted[\"row_in_case\"] > row_idx_after)]\n",
    "    if sub.empty:\n",
    "        return np.nan\n",
    "    nxt_q = sub.loc[sub[\"status\"] == \"queued\"]\n",
    "    if not nxt_q.empty:\n",
    "        return nxt_q.iloc[0][\"activity\"]\n",
    "    # No queued afterwards; for packaging gateway the case may complete next\n",
    "    nxt_c = sub.loc[sub[\"status\"] == \"COMPLETE\"]\n",
    "    if not nxt_c.empty:\n",
    "        return \"END\"\n",
    "    return np.nan\n",
    "\n",
    "gates[\"next_activity\"] = [\n",
    "    next_step_after_gateway(sim_run, cid, r)\n",
    "    for sim_run, cid, r in gates[[\"simulation_run\",\"case_id\",\"row_in_case\"]].itertuples(index=False, name=None)\n",
    "]\n",
    "\n",
    "# Empirical routing per gateway label (aggregate across all simulation runs)\n",
    "routing_emp = (\n",
    "    gates.groupby(\"activity\")[\"next_activity\"]\n",
    "         .value_counts(normalize=True, dropna=True)\n",
    "         .rename(\"prob\")\n",
    "         .reset_index()\n",
    ")\n",
    "\n",
    "# Expected (from your config)\n",
    "expected = {\n",
    "    \"QC_AFTER_MOULDING\":  {\"MOULDING\": 0.05, \"ASSEMBLY_1\": 0.95},\n",
    "    \"QC_AFTER_ASSEMBLY1\": {\"ASSEMBLY_1\": 0.05, \"ASSEMBLY_2\": 0.95},\n",
    "    \"QC_AFTER_ASSEMBLY2\": {\"ASSEMBLY_2\": 0.05, \"SORTING\":    0.95},\n",
    "    \"QC_AFTER_SORTING\":   {\"SORTING\":   0.05, \"PACKAGING\":   0.95},\n",
    "    \"QC_AFTER_PACKAGING\": {\"PACKAGING\": 0.05, \"END\":         0.95},\n",
    "}\n",
    "routing_exp = pd.DataFrame(\n",
    "    [{\"activity\": g, \"next_activity\": nxt, \"expected\": p}\n",
    "     for g, dd in expected.items() for nxt, p in dd.items()]\n",
    ")\n",
    "\n",
    "routing = (routing_exp\n",
    "           .merge(routing_emp, on=[\"activity\",\"next_activity\"], how=\"left\")\n",
    "           .fillna({\"prob\": 0.0}))\n",
    "routing[\"diff\"] = routing[\"prob\"] - routing[\"expected\"]\n",
    "\n",
    "print(\"\\nRouting empirical vs expected (position-based):\")\n",
    "print(routing.sort_values([\"activity\",\"next_activity\"]))\n",
    "\n",
    "# How many gateways had 0-wait to the next station?\n",
    "merge_for_wait = gates.merge(\n",
    "    inst[[\"simulation_run\",\"case_id\",\"activity\",\"queued_ts\",\"start_ts\"]],\n",
    "    left_on=[\"simulation_run\",\"case_id\",\"next_activity\"], \n",
    "    right_on=[\"simulation_run\",\"case_id\",\"activity\"],\n",
    "    how=\"left\", suffixes=(\"_gate\",\"_next\")\n",
    ")\n",
    "zero_wait_share = (merge_for_wait[\"start_ts\"] - merge_for_wait[\"timestamp\"] <= 1e-9).mean()\n",
    "print(\"Share of gateways with immediate (zero-wait) handoff:\", zero_wait_share)\n",
    "\n",
    "# --- 5) service-time by resource ---\n",
    "svc = inst.dropna(subset=[\"resource_name\",\"service\"]).copy()\n",
    "svc_stats = svc.groupby(\"resource_name\")[\"service\"].agg([\"count\",\"mean\",\"std\",\"min\",\"max\"]).reset_index()\n",
    "\n",
    "# Rough exponential check: for Exp, mean ≈ std; ratio near 1 is indicative (not proof)\n",
    "svc_stats[\"std_over_mean\"] = svc_stats[\"std\"]/svc_stats[\"mean\"]\n",
    "\n",
    "# --- 6) utilization & throughput ---\n",
    "# Calculate T per simulation run and average\n",
    "T_per_run = df.groupby(\"simulation_run\")[\"timestamp\"].max()\n",
    "T = T_per_run.mean()  # average simulation horizon\n",
    "\n",
    "busy = (\n",
    "    svc.groupby(\"resource_name\", as_index=False)[\"service\"]\n",
    "       .sum()\n",
    "       .rename(columns={\"service\":\"busy_time\"})\n",
    ")\n",
    "busy[\"utilization\"] = busy[\"busy_time\"] / (T * len(T_per_run))  # total busy time / (avg_T * num_runs)\n",
    "\n",
    "# Station-level KPIs\n",
    "station = inst.groupby(\"activity\").agg(\n",
    "    arrivals=(\"activity\",\"size\"),\n",
    "    mean_wait=(\"wait\",\"mean\"),\n",
    "    mean_service=(\"service\",\"mean\"),\n",
    "    mean_sojourn=(\"sojourn\",\"mean\")\n",
    ").reset_index()\n",
    "\n",
    "# --- 7) Little's Law check: L ≈ λ W at station level ---\n",
    "# λ = arrivals / T; W = mean_sojourn at station; L_hat = λ*W\n",
    "station[\"lambda\"] = station[\"arrivals\"] / (T * len(T_per_run))\n",
    "station[\"L_hat\"] = station[\"lambda\"] * station[\"mean_sojourn\"]\n",
    "\n",
    "# --- Summaries to print or save ---\n",
    "print(\"\\nFIFO violations per station per run (should be 0):\")\n",
    "print(fifo_check.groupby(\"activity\")[\"fifo_violations\"].sum().sort_values(ascending=False).head(10))\n",
    "\n",
    "print(\"\\nRouting empirical vs expected (diff near 0):\")\n",
    "print(routing.sort_values([\"activity\",\"next_activity\"]))\n",
    "\n",
    "print(\"\\nService by resource (std/mean ~ 1 for Exp):\")\n",
    "print(svc_stats.sort_values(\"std_over_mean\"))\n",
    "\n",
    "print(\"\\nResource utilization (sanity):\")\n",
    "print(busy.sort_values(\"utilization\", ascending=False).head(10))\n",
    "\n",
    "print(\"\\nStation KPIs + Little's Law proxy:\")\n",
    "print(station.sort_values(\"L_hat\", ascending=False).head(10))\n",
    "\n",
    "# --- Stability audit: capacity vs offered load, with warm-up trim ---\n",
    "warmup_fraction = 0.05\n",
    "\n",
    "def analyze_stability_for_run(run_df, run_id):\n",
    "    \"\"\"Analyze stability for a single simulation run\"\"\"\n",
    "    warmup = run_df[\"timestamp\"].max() * warmup_fraction\n",
    "    inst_run = inst[inst[\"simulation_run\"] == run_id].copy()\n",
    "    inst_ss = inst_run[inst_run[\"queued_ts\"] >= warmup].copy()\n",
    "    \n",
    "    if inst_ss.empty:\n",
    "        return None\n",
    "        \n",
    "    T_eff = run_df[\"timestamp\"].max() - warmup\n",
    "    \n",
    "    # Per-station arrival rate λ_station (jobs/min)\n",
    "    arrivals = inst_ss.groupby(\"activity\")[\"activity\"].size().rename(\"arrivals\").reset_index()\n",
    "    arrivals[\"lambda_station\"] = arrivals[\"arrivals\"] / T_eff\n",
    "    \n",
    "    # Mean service time per (activity, resource) then aggregate to station capacity\n",
    "    svc_ss = inst_ss.dropna(subset=[\"resource_name\",\"service\"]).copy()\n",
    "    if svc_ss.empty:\n",
    "        return None\n",
    "        \n",
    "    rs = (svc_ss.groupby([\"activity\",\"resource_name\"])[\"service\"]\n",
    "                .mean()\n",
    "                .rename(\"mean_service\")\n",
    "                .reset_index())\n",
    "    \n",
    "    # Station capacity (jobs/min) = sum over resources of 1 / E[S_resource]\n",
    "    cap = (rs.assign(mu=lambda d: 1.0 / d[\"mean_service\"])\n",
    "             .groupby(\"activity\")[\"mu\"].sum()\n",
    "             .rename(\"capacity\")\n",
    "             .reset_index())\n",
    "    \n",
    "    # Merge and compute utilization proxy and safety margin\n",
    "    stab = (arrivals.merge(cap, on=\"activity\", how=\"left\"))\n",
    "    stab[\"rho_hat\"] = stab[\"lambda_station\"] / stab[\"capacity\"]\n",
    "    stab[\"headroom\"] = 1.0 - stab[\"rho_hat\"]\n",
    "    stab[\"simulation_run\"] = run_id\n",
    "    \n",
    "    return stab\n",
    "\n",
    "# Analyze stability for each run and combine\n",
    "stability_results = []\n",
    "for run_id in df[\"simulation_run\"].unique():\n",
    "    run_df = df[df[\"simulation_run\"] == run_id]\n",
    "    stab = analyze_stability_for_run(run_df, run_id)\n",
    "    if stab is not None:\n",
    "        stability_results.append(stab)\n",
    "\n",
    "if stability_results:\n",
    "    combined_stability = pd.concat(stability_results, ignore_index=True)\n",
    "    avg_stability = combined_stability.groupby(\"activity\").agg({\n",
    "        \"rho_hat\": \"mean\",\n",
    "        \"headroom\": \"mean\",\n",
    "        \"lambda_station\": \"mean\",\n",
    "        \"capacity\": \"mean\"\n",
    "    }).reset_index()\n",
    "    \n",
    "    print(\"\\nAverage stability headroom by station across all runs:\")\n",
    "    print(avg_stability.sort_values(\"rho_hat\", ascending=False))\n",
    "else:\n",
    "    print(\"\\nNo stability data available\")\n",
    "\n",
    "# --- Queue trend analysis ---\n",
    "def queue_trace(inst_df, act, run_id):\n",
    "    run_data = inst_df[inst_df[\"simulation_run\"] == run_id]\n",
    "    g = run_data[run_data[\"activity\"]==act][[\"queued_ts\",\"start_ts\"]].copy()\n",
    "    if g.empty: \n",
    "        return None\n",
    "    ups   = g.groupby(\"queued_ts\").size().rename(\"delta\")\n",
    "    downs = (g.groupby(\"start_ts\").size() * -1).rename(\"delta\")\n",
    "    deltas = pd.concat([ups, downs], axis=0).groupby(level=0).sum().sort_index()\n",
    "    tr = deltas.cumsum().reset_index().rename(columns={\"index\":\"time\",\"delta\":\"qlen\"})\n",
    "    tr[\"qlen\"] = tr[\"qlen\"].clip(lower=0)\n",
    "    return tr\n",
    "\n",
    "def end_trend_slope(trace, tail_frac=0.2):\n",
    "    if trace is None or len(trace) < 5: \n",
    "        return np.nan\n",
    "    n0 = int(len(trace)*(1-tail_frac))\n",
    "    tail = trace.iloc[max(n0,0):].copy()\n",
    "    if len(tail) < 3: \n",
    "        return np.nan\n",
    "    # simple least-squares slope of qlen on time\n",
    "    x = tail[\"time\"].values\n",
    "    y = tail[\"qlen\"].values\n",
    "    A = np.vstack([x, np.ones_like(x)]).T\n",
    "    slope, _ = np.linalg.lstsq(A, y, rcond=None)[0]\n",
    "    return slope  # jobs per minute near the end\n",
    "\n",
    "# Analyze queue trends per run and activity\n",
    "trend_results = []\n",
    "for run_id in df[\"simulation_run\"].unique():\n",
    "    run_inst = inst[inst[\"simulation_run\"] == run_id]\n",
    "    warmup = run_inst[\"queued_ts\"].max() * warmup_fraction\n",
    "    inst_ss_run = run_inst[run_inst[\"queued_ts\"] >= warmup]\n",
    "    \n",
    "    acts = sorted(inst_ss_run[\"activity\"].unique())\n",
    "    for act in acts:\n",
    "        tr = queue_trace(inst_ss_run, act, run_id)\n",
    "        slope = end_trend_slope(tr, tail_frac=0.3)\n",
    "        trend_results.append({\n",
    "            \"simulation_run\": run_id, \n",
    "            \"activity\": act, \n",
    "            \"end_slope_q_per_min\": slope\n",
    "        })\n",
    "\n",
    "trend_df = pd.DataFrame(trend_results)\n",
    "avg_trend = trend_df.groupby(\"activity\")[\"end_slope_q_per_min\"].mean().reset_index()\n",
    "\n",
    "print(\"\\nAverage queue end-trend slope across all runs (jobs/min; ≈0 is good):\")\n",
    "print(avg_trend.sort_values(\"end_slope_q_per_min\", ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e767d0d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info] runs found: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "[Info] discovery runs: [0, 1, 2, 3, 4, 5, 6, 7, 8] | held-out run: [9]\n",
      "[Info] cases after trim — discovery: 1292, held-out: 1225\n",
      "[Info] instances — discovery: 56749 | held-out: 6450\n",
      "[Saved] discovery_eventlog.csv, heldout_eventlog.csv\n",
      "[Discovery] Inductive Miner (IMf)…\n",
      "[Info] Inductive Miner returned: ProcessTree\n",
      "[Saved] results\\model_inductive.pnml\n",
      "[Saved] model_inductive.png\n",
      "[Discovery] DFG (frequency + performance)…\n",
      "[Saved] dfg_frequency.png\n",
      "[Saved] dfg_edges.csv  (freq + mean_time)\n",
      "\n",
      "=== Summary ===\n",
      "Traces (discovery): 10766 | Traces (held-out): 1225\n",
      "Activities (discovery): 5\n",
      "DFG edges: 10\n",
      "Files saved in: c:\\Users\\990215322\\Desktop\\MuProMAC\\results\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Inductive Miner + DFG (PM4Py)\n",
    "# End-to-end discovery from simulator CSVs\n",
    "# =========================\n",
    "\n",
    "# --- installs (safe to rerun) ---\n",
    "import sys, subprocess, pkgutil\n",
    "def _pip(pkg):\n",
    "    if pkg not in {m.name for m in pkgutil.iter_modules()}:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", pkg])\n",
    "\n",
    "for p in [\"pm4py\", \"graphviz\"]:\n",
    "    try:\n",
    "        _pip(p)\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] Could not auto-install {p}: {e}\")\n",
    "\n",
    "# --- imports ---\n",
    "import os, glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from pm4py.objects.conversion.log import converter as log_converter\n",
    "from pm4py.algo.discovery.inductive import algorithm as inductive_miner\n",
    "from pm4py.objects.petri_net.exporter import exporter as pnml_exporter\n",
    "from pm4py.visualization.petri_net import visualizer as pn_vis\n",
    "\n",
    "from pm4py.algo.discovery.dfg import algorithm as dfg_discovery\n",
    "from pm4py.visualization.dfg import visualizer as dfg_vis\n",
    "\n",
    "# =========================\n",
    "# CONFIG\n",
    "# =========================\n",
    "LOGS_GLOB        = \"results/251020FIFO_l0.28_actuator_manufacturing_with_rework.csv\"   # <-- adjust if your files live elsewhere\n",
    "SCENARIO_FILTER  = None              # e.g., \"actuator_manufacturing_with_rework\" or None\n",
    "USE_ALL_RUNS     = True              # use all runs for discovery except the held-out\n",
    "HOLDOUT_IS_LAST  = True              # treat the last run id as held-out (ignored if not splitting)\n",
    "HOLDOUT_RUN      = None              # e.g., 6  (used if HOLDOUT_IS_LAST == False)\n",
    "WARMUP_FRAC      = 0.10              # whole-case trim: drop cases starting before 10% of run span\n",
    "COOLDOWN_FRAC    = 0.02              # drop cases ending after last 2% of span\n",
    "EPS              = 1e-9              # tiny epsilon for time comparisons\n",
    "\n",
    "OUT_DIR          = \"results\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "# =========================\n",
    "# LOAD CSVs\n",
    "# =========================\n",
    "files = sorted(glob.glob(LOGS_GLOB))\n",
    "if not files:\n",
    "    raise FileNotFoundError(f\"No CSVs matched {LOGS_GLOB}\")\n",
    "\n",
    "dfs = []\n",
    "for f in files:\n",
    "    d = pd.read_csv(f)\n",
    "    # required minimal columns\n",
    "    required = {\"timestamp\",\"status\",\"case_id\",\"activity\"}\n",
    "    missing = required - set(d.columns)\n",
    "    if missing:\n",
    "        raise ValueError(f\"{f} is missing required columns: {missing}\")\n",
    "    if SCENARIO_FILTER and \"scenario\" in d.columns:\n",
    "        d = d[d[\"scenario\"] == SCENARIO_FILTER]\n",
    "        if d.empty:\n",
    "            continue\n",
    "    dfs.append(d)\n",
    "\n",
    "if not dfs:\n",
    "    raise RuntimeError(\"After filtering, no logs remain.\")\n",
    "\n",
    "df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# parse numeric time columns\n",
    "df[\"timestamp\"] = pd.to_numeric(df[\"timestamp\"], errors=\"coerce\")\n",
    "if \"end_time\" in df.columns:\n",
    "    df[\"end_time\"] = pd.to_numeric(df[\"end_time\"], errors=\"coerce\")\n",
    "\n",
    "# ensure simulation_run exists\n",
    "if \"simulation_run\" not in df.columns:\n",
    "    df[\"simulation_run\"] = 0\n",
    "\n",
    "all_runs = sorted(df[\"simulation_run\"].dropna().unique().tolist())\n",
    "if not all_runs:\n",
    "    all_runs = [0]\n",
    "\n",
    "if HOLDOUT_IS_LAST:\n",
    "    HOLDOUT_RUN = all_runs[-1]\n",
    "elif HOLDOUT_RUN is None:\n",
    "    HOLDOUT_RUN = all_runs[-1]\n",
    "\n",
    "disc_runs = [r for r in all_runs if r != HOLDOUT_RUN] if USE_ALL_RUNS else [all_runs[0]]\n",
    "held_runs = [HOLDOUT_RUN]\n",
    "\n",
    "print(f\"[Info] runs found: {all_runs}\")\n",
    "print(f\"[Info] discovery runs: {disc_runs} | held-out run: {held_runs}\")\n",
    "\n",
    "# keep only columns we need downstream\n",
    "keep_cols = [c for c in [\"simulation_run\",\"timestamp\",\"status\",\"case_id\",\"activity\",\"resource\",\"end_time\"] if c in df.columns]\n",
    "df = df[keep_cols].copy()\n",
    "\n",
    "# =========================\n",
    "# WHOLE-CASE TRIM (per run)\n",
    "# =========================\n",
    "def trim_cases_whole(df_run, warmup_frac=WARMUP_FRAC, cooldown_frac=COOLDOWN_FRAC):\n",
    "    t_max = df_run[\"timestamp\"].max()\n",
    "    t0 = t_max * warmup_frac\n",
    "    t1 = t_max * (1.0 - cooldown_frac)\n",
    "\n",
    "    starts = (df_run[df_run[\"status\"]==\"START\"]\n",
    "              .groupby(\"case_id\")[\"timestamp\"].min().rename(\"case_start\"))\n",
    "    last   = df_run.groupby(\"case_id\")[\"timestamp\"].max().rename(\"case_last\")\n",
    "    ends   = (df_run[df_run[\"status\"]==\"COMPLETE\"]\n",
    "              .groupby(\"case_id\")[\"timestamp\"].max().rename(\"case_end\"))\n",
    "    meta = pd.concat([starts, ends, last], axis=1).reset_index()\n",
    "    meta[\"case_end_fallback\"] = meta[\"case_end\"].fillna(meta[\"case_last\"])\n",
    "\n",
    "    keep_ids = meta[(meta[\"case_start\"] >= t0) & (meta[\"case_end_fallback\"] <= t1)][\"case_id\"]\n",
    "    return df_run[df_run[\"case_id\"].isin(keep_ids)].copy()\n",
    "\n",
    "def trim_all_runs(df_any):\n",
    "    pieces = []\n",
    "    for r in sorted(df_any[\"simulation_run\"].unique()):\n",
    "        dr = df_any[df_any[\"simulation_run\"]==r].copy()\n",
    "        pieces.append(trim_cases_whole(dr))\n",
    "    return pd.concat(pieces, ignore_index=True)\n",
    "\n",
    "df_disc_raw = df[df[\"simulation_run\"].isin(disc_runs)].copy()\n",
    "df_hold_raw = df[df[\"simulation_run\"].isin(held_runs)].copy()\n",
    "df_disc = trim_all_runs(df_disc_raw)\n",
    "df_hold = trim_all_runs(df_hold_raw)\n",
    "\n",
    "print(f\"[Info] cases after trim — discovery: {df_disc['case_id'].nunique()}, held-out: {df_hold['case_id'].nunique()}\")\n",
    "\n",
    "# =========================\n",
    "# RECONSTRUCT TASK INSTANCES (queued → running)\n",
    "# =========================\n",
    "def pair_instances(df_run):\n",
    "    # keep only task lifecycle rows (exclude gateway + START/COMPLETE)\n",
    "    mask = (df_run[\"activity\"].ne(\"START\")) & (df_run[\"status\"].isin([\"queued\",\"running\"]))\n",
    "    task_rows = df_run[mask].copy()\n",
    "    task_rows = task_rows.sort_values([\"simulation_run\",\"case_id\",\"activity\",\"timestamp\"])\n",
    "\n",
    "    queued  = task_rows[task_rows[\"status\"]==\"queued\"].copy()\n",
    "    queued[\"occ_q\"] = queued.groupby([\"simulation_run\",\"case_id\",\"activity\"]).cumcount()\n",
    "\n",
    "    running = task_rows[task_rows[\"status\"]==\"running\"].copy()\n",
    "    running[\"occ_r\"] = running.groupby([\"simulation_run\",\"case_id\",\"activity\"]).cumcount()\n",
    "\n",
    "    inst = pd.merge(\n",
    "        queued[[\"simulation_run\",\"case_id\",\"activity\",\"occ_q\",\"timestamp\"]],\n",
    "        running[[\"simulation_run\",\"case_id\",\"activity\",\"occ_r\",\"timestamp\",\"end_time\",\"resource\"]],\n",
    "        left_on=[\"simulation_run\",\"case_id\",\"activity\",\"occ_q\"],\n",
    "        right_on=[\"simulation_run\",\"case_id\",\"activity\",\"occ_r\"],\n",
    "        how=\"inner\",\n",
    "        suffixes=(\"_queued\",\"_start\")\n",
    "    ).drop(columns=[\"occ_q\",\"occ_r\"])\n",
    "\n",
    "    inst = inst.rename(columns={\n",
    "        \"timestamp_queued\":\"queued_ts\",\n",
    "        \"timestamp_start\":\"start_ts\",\n",
    "        \"end_time\":\"end_ts\",\n",
    "        \"resource\":\"org:resource\"\n",
    "    })\n",
    "    # durations (sanity)\n",
    "    inst[\"wait\"]    = inst[\"start_ts\"] - inst[\"queued_ts\"]\n",
    "    inst[\"service\"] = inst[\"end_ts\"]   - inst[\"start_ts\"]\n",
    "    inst[\"sojourn\"] = inst[\"end_ts\"]   - inst[\"queued_ts\"]\n",
    "    inst = inst[(inst[\"wait\"]>=-EPS) & (inst[\"service\"]>=-EPS) & (inst[\"sojourn\"]>=-EPS)].copy()\n",
    "    return inst\n",
    "\n",
    "inst_disc = pair_instances(df_disc)\n",
    "inst_hold = pair_instances(df_hold)\n",
    "\n",
    "print(f\"[Info] instances — discovery: {len(inst_disc)} | held-out: {len(inst_hold)}\")\n",
    "\n",
    "# =========================\n",
    "# BUILD PM4Py EVENT LOG with lifecycle\n",
    "# =========================\n",
    "def build_event_df(inst, df_raw):\n",
    "    \"\"\"Build event log including START/END boundaries\"\"\"\n",
    "    \n",
    "    # 1) Task lifecycle events (start and complete)\n",
    "    start_events = inst.rename(columns={\n",
    "        \"start_ts\":\"time:timestamp\",\n",
    "        \"activity\":\"concept:name\"\n",
    "    })[[\"simulation_run\",\"case_id\",\"concept:name\",\"time:timestamp\",\"org:resource\"]].copy()\n",
    "    start_events[\"lifecycle:transition\"] = \"start\"\n",
    "\n",
    "    complete_events = inst.rename(columns={\n",
    "        \"end_ts\":\"time:timestamp\",\n",
    "        \"activity\":\"concept:name\"\n",
    "    })[[\"simulation_run\",\"case_id\",\"concept:name\",\"time:timestamp\",\"org:resource\"]].copy()\n",
    "    complete_events[\"lifecycle:transition\"] = \"complete\"\n",
    "\n",
    "    # 2) Add START events (case arrival) - these mark the beginning of each case\n",
    "    start_rows = df_raw[df_raw[\"status\"] == \"START\"].copy()\n",
    "    start_rows = start_rows.rename(columns={\n",
    "        \"timestamp\": \"time:timestamp\",\n",
    "        \"activity\": \"concept:name\"\n",
    "    })\n",
    "    start_rows[\"lifecycle:transition\"] = \"complete\"  # START is instantaneous\n",
    "    start_rows[\"org:resource\"] = None\n",
    "    start_rows = start_rows[[\"simulation_run\",\"case_id\",\"concept:name\",\"time:timestamp\",\"org:resource\",\"lifecycle:transition\"]]\n",
    "\n",
    "    # 3) Add END events (case completion) - these mark the end of each case\n",
    "    end_rows = df_raw[df_raw[\"status\"] == \"COMPLETE\"].copy()\n",
    "    end_rows = end_rows.rename(columns={\n",
    "        \"timestamp\": \"time:timestamp\",\n",
    "        \"activity\": \"concept:name\"  \n",
    "    })\n",
    "    end_rows[\"lifecycle:transition\"] = \"complete\"\n",
    "    end_rows[\"org:resource\"] = None\n",
    "    end_rows = end_rows[[\"simulation_run\",\"case_id\",\"concept:name\",\"time:timestamp\",\"org:resource\",\"lifecycle:transition\"]]\n",
    "\n",
    "    # 4) Combine all events\n",
    "    ev = pd.concat([start_rows, start_events, complete_events, end_rows], ignore_index=True)\n",
    "    \n",
    "    # PM4Py keys\n",
    "    ev = ev.rename(columns={\"case_id\":\"case:concept:name\"})\n",
    "    ev[\"trace_id\"] = ev[\"simulation_run\"].astype(str) + \"-\" + ev[\"case:concept:name\"].astype(str)\n",
    "    \n",
    "    # Sort by case and timestamp to ensure proper ordering\n",
    "    ev = ev.sort_values([\"trace_id\", \"time:timestamp\"]).reset_index(drop=True)\n",
    "    \n",
    "    # Convert timestamps\n",
    "    ev[\"time:timestamp\"] = pd.to_datetime(ev[\"time:timestamp\"], unit=\"m\", origin=\"unix\", errors=\"coerce\")\n",
    "    \n",
    "    return ev\n",
    "\n",
    "ev_disc = build_event_df(inst_disc, df_disc)\n",
    "ev_hold = build_event_df(inst_hold, df_hold)\n",
    "\n",
    "# Save CSV event logs (optional, useful to inspect)\n",
    "ev_disc.to_csv(os.path.join(OUT_DIR, \"discovery_eventlog.csv\"), index=False)\n",
    "ev_hold.to_csv(os.path.join(OUT_DIR, \"heldout_eventlog.csv\"), index=False)\n",
    "print(\"[Saved] discovery_eventlog.csv, heldout_eventlog.csv\")\n",
    "\n",
    "# PM4Py event log objects\n",
    "params = {log_converter.Variants.TO_EVENT_LOG.value.Parameters.CASE_ID_KEY: \"trace_id\"}\n",
    "log_disc = log_converter.apply(ev_disc, variant=log_converter.Variants.TO_EVENT_LOG, parameters=params)\n",
    "log_hold = log_converter.apply(ev_hold, variant=log_converter.Variants.TO_EVENT_LOG, parameters=params)\n",
    "\n",
    "# =========================\n",
    "# INDUCTIVE MINER (IMf) -> convert ProcessTree to Petri net\n",
    "# =========================\n",
    "print(\"[Discovery] Inductive Miner (IMf)…\")\n",
    "from pm4py.objects.conversion.process_tree import converter as pt_converter\n",
    "\n",
    "# 1) Discover process tree\n",
    "ptree = inductive_miner.apply(log_disc, variant=inductive_miner.Variants.IMf)\n",
    "print(\"[Info] Inductive Miner returned:\", type(ptree).__name__)  # should be 'ProcessTree'\n",
    "\n",
    "# 2) Convert tree -> Petri net\n",
    "net_i, im_i, fm_i = pt_converter.apply(ptree, variant=pt_converter.Variants.TO_PETRI_NET)\n",
    "\n",
    "# 3) Save PNML and PNG\n",
    "pnml_ind = os.path.join(OUT_DIR, \"model_inductive.pnml\")\n",
    "pnml_exporter.apply(net_i, im_i, pnml_ind, final_marking=fm_i)\n",
    "print(f\"[Saved] {pnml_ind}\")\n",
    "\n",
    "try:\n",
    "    gviz_i = pn_vis.apply(net_i, im_i, fm_i)\n",
    "    pn_vis.save(gviz_i, os.path.join(OUT_DIR, \"model_inductive.png\"))\n",
    "    print(\"[Saved] model_inductive.png\")\n",
    "except Exception as e:\n",
    "    print(f\"[WARN] Could not render Petri net PNG (Graphviz missing/not on PATH): {e}\")\n",
    "\n",
    "\n",
    "# =========================\n",
    "# DFG (frequency + performance)\n",
    "# =========================\n",
    "print(\"[Discovery] DFG (frequency + performance)…\")\n",
    "\n",
    "# frequency DFG\n",
    "dfg_freq = dfg_discovery.apply(log_disc, variant=dfg_discovery.Variants.FREQUENCY)\n",
    "# performance DFG (edge performance as mean time between activities)\n",
    "dfg_perf = dfg_discovery.apply(log_disc, variant=dfg_discovery.Variants.PERFORMANCE)\n",
    "\n",
    "# visualize frequency DFG\n",
    "try:\n",
    "    gviz_dfg = dfg_vis.apply(dfg_freq, log_disc, variant=dfg_vis.Variants.FREQUENCY)\n",
    "    dfg_vis.save(gviz_dfg, os.path.join(OUT_DIR, \"dfg_frequency.png\"))\n",
    "    print(\"[Saved] dfg_frequency.png\")\n",
    "except Exception as e:\n",
    "    print(f\"[WARN] Could not render DFG PNG (Graphviz missing/not on PATH): {e}\")\n",
    "\n",
    "# export DFG edges to CSV (frequency + performance)\n",
    "def dfg_to_frame(dfg_dict, col_name):\n",
    "    rows = []\n",
    "    for (a,b), val in dfg_dict.items():\n",
    "        rows.append({\"from\": a, \"to\": b, col_name: val})\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "dfg_freq_df = dfg_to_frame(dfg_freq, \"frequency\")\n",
    "dfg_perf_df = dfg_to_frame(dfg_perf, \"mean_time\")  # PM4Py stores average durations here\n",
    "\n",
    "dfg_edges = pd.merge(dfg_freq_df, dfg_perf_df, on=[\"from\",\"to\"], how=\"outer\")\n",
    "dfg_edges = dfg_edges.sort_values([\"from\",\"to\"]).reset_index(drop=True)\n",
    "dfg_edges.to_csv(os.path.join(OUT_DIR, \"dfg_edges.csv\"), index=False)\n",
    "print(\"[Saved] dfg_edges.csv  (freq + mean_time)\")\n",
    "\n",
    "# quick summary\n",
    "print(\"\\n=== Summary ===\")\n",
    "print(f\"Traces (discovery): {len(log_disc)} | Traces (held-out): {len(log_hold)}\")\n",
    "print(f\"Activities (discovery): {ev_disc['concept:name'].nunique()}\")\n",
    "print(f\"DFG edges: {len(dfg_edges)}\")\n",
    "print(\"Files saved in:\", os.path.abspath(OUT_DIR))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1676e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Graphviz reachable (created process_visualizations/_graphviz_ok.png)\n",
      "======================================================================\n",
      "🔨 COMPLETE PROCESS MINING - Run 0\n",
      "======================================================================\n",
      "⚠️ Event log conversion failed: list indices must be integers or slices, not str\n",
      "📊 Using DataFrame directly: 1377 events, 1377 cases\n",
      "🔄 Discovering Directly-Follows Graph...\n",
      "✅ DFG discovered: 0 direct-follows relations\n",
      "🔄 Discovering process with Inductive Miner...\n",
      "✅ Inductive Miner model discovered\n",
      "🔄 Discovering process with Heuristics Miner...\n",
      "✅ Heuristics Miner model discovered\n",
      "🔍 Analyzing process variants...\n",
      "📋 Found 1 unique process variants\n",
      "\n",
      "Top 10 most frequent variants:\n",
      " 1. Count: 1377 - END\n",
      "📊 Calculating process metrics...\n",
      "\n",
      "📈 Process Metrics:\n",
      "   Cases: 1377\n",
      "   Average case duration: 0.00 minutes\n",
      "   Throughput: 16.66 cases/hour\n",
      "   Unique activities: 1\n",
      "\n",
      "🏭 Most frequent activities:\n",
      "   END: 1377 occurrences\n",
      "⚖️ Comparing discovery methods...\n",
      "\n",
      "🔬 Discovery Method Comparison:\n",
      "\n",
      "DFG:\n",
      "  num_activities: 0\n",
      "  num_relations: 0\n",
      "  start_activities: 1\n",
      "  end_activities: 1\n",
      "  description: Directly-Follows Graph - frequency-based relations\n",
      "\n",
      "INDUCTIVE:\n",
      "  num_places: 2\n",
      "  num_transitions: 1\n",
      "  num_arcs: 2\n",
      "  model_complexity: 3\n",
      "  description: Inductive Miner - sound process tree converted to Petri net\n",
      "\n",
      "HEURISTICS:\n",
      "  description: Heuristics Net - dependency-based with frequency thresholds\n",
      "💾 Saving models to discovered_models/...\n",
      "✅ Saved DFG relations to dfg_relations.csv\n",
      "✅ Saved Inductive Miner model to inductive_model.pnml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\990215322\\AppData\\Local\\miniconda3\\envs\\mupro\\Lib\\site-packages\\pm4py\\utils.py:991: UserWarning: Install the optional requirement `rustxes` to import/export files faster.\n",
      "  warnings.warn(\"Install the optional requirement `rustxes` to import/export files faster.\")\n",
      "c:\\Users\\990215322\\AppData\\Local\\miniconda3\\envs\\mupro\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "exporting log, completed traces :: 100%|██████████| 1377/1377 [00:00<00:00, 12689.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved event log to event_log.xes\n",
      "💾 Saving visualizations as images...\n",
      "⚠️ PM4Py visualization failed: string indices must be integers, not 'str'\n",
      "🔄 Trying alternative approach...\n",
      "🎨 Creating visualizations using graphviz directly...\n",
      "✅ Saved DFG as dfg.png\n",
      "✅ Saved Process Flow as process_flow.png\n",
      "\n",
      "🎉 PROCESS MINING COMPLETE!\n",
      "\n",
      "🎉 ALL DONE! Check these folders for results:\n",
      "📁 'process_visualizations' - PNG images of process models\n",
      "📁 'discovered_models' - CSV, PNML, and XES files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"PM4PY_DISABLE_CVXOPT\"] = \"1\"\n",
    "os.environ[\"PM4PY_LP_SOLVER\"] = \"scipy\"\n",
    "\n",
    "import pm4py\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "from pm4py.objects.conversion.log import converter as xes_converter\n",
    "\n",
    "PORTABLE = r\"C:\\Users\\990215322\\Downloads\\windows_10_cmake_Release_Graphviz-14.0.2-win64 (1)\\Graphviz-14.0.2-win64\"\n",
    "os.environ[\"PATH\"] = PORTABLE + r\"\\bin;\" + os.environ.get(\"PATH\", \"\")\n",
    "os.environ[\"GV_PLUGIN_PATH\"] = PORTABLE + r\"\\lib\\graphviz\"\n",
    "os.environ[\"GRAPHVIZ_DOT\"] = PORTABLE + r\"\\bin\\dot.exe\"\n",
    "\n",
    "os.makedirs(\"process_visualizations\", exist_ok=True)\n",
    "\n",
    "# --- quick Graphviz smoke test ---\n",
    "try:\n",
    "    import graphviz as _gv\n",
    "    _gv.Source(\"digraph{A->B}\").render(\"process_visualizations/_graphviz_ok\", format=\"png\", cleanup=True)\n",
    "    print(\"[OK] Graphviz reachable (created process_visualizations/_graphviz_ok.png)\")\n",
    "except Exception as e:\n",
    "    print(\"[WARN] Graphviz smoke test failed:\", e)\n",
    "\n",
    "class ProcessMiner:\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        self.event_log = None\n",
    "        self.models = {}\n",
    "        \n",
    "    def prepare_event_log(self, run_id=None):\n",
    "        \"\"\"\n",
    "        Build one event per activity instance (complete at end_ts).\n",
    "        This avoids the raw status confusion (queued/running/COMPLETE).\n",
    "        \"\"\"\n",
    "        df = self.df.copy()\n",
    "        if run_id is not None:\n",
    "            df = df[df['simulation_run'] == run_id].copy()\n",
    "\n",
    "        # --------- 1) robust instance reconstruction ----------\n",
    "        case_col_src = 'case_id'\n",
    "        task_rows = df[\n",
    "            (df['status'].isin(['queued', 'running'])) &\n",
    "            (df['activity'].ne('START')) &\n",
    "            (df['activity'].ne('END'))\n",
    "        ].copy()\n",
    "\n",
    "        task_rows = task_rows.sort_values([case_col_src, 'activity', 'timestamp'])\n",
    "\n",
    "        queued = (task_rows[task_rows['status'] == 'queued']\n",
    "                .assign(idx=lambda d: d.groupby([case_col_src, 'activity']).cumcount())\n",
    "                [[case_col_src, 'activity', 'timestamp', 'idx']]\n",
    "                .rename(columns={'timestamp': 'queued_ts'}))\n",
    "\n",
    "        running = (task_rows[task_rows['status'] == 'running']\n",
    "                .assign(idx=lambda d: d.groupby([case_col_src, 'activity']).cumcount())\n",
    "                [[case_col_src, 'activity', 'timestamp', 'end_time', 'resource', 'idx']]\n",
    "                .rename(columns={'timestamp': 'start_ts',\n",
    "                                    'end_time': 'end_ts',\n",
    "                                    'resource': 'org:resource'}))\n",
    "\n",
    "        # Keep all running (completed services); fill missing queued as zero-wait\n",
    "        inst = pd.merge(running, queued, on=[case_col_src, 'activity', 'idx'], how='left')\n",
    "        inst['queued_ts'] = inst['queued_ts'].fillna(inst['start_ts'])\n",
    "\n",
    "        # sanity: drop negatives\n",
    "        inst = inst[inst['end_ts'] >= inst['start_ts']].copy()\n",
    "\n",
    "        # If we are using multiple runs, make cross-run-unique case id\n",
    "        if run_id is None:\n",
    "            inst['case:concept:name'] = (\n",
    "                df['simulation_run'].astype(str) + '_' + inst[case_col_src].astype(str)\n",
    "            )\n",
    "        else:\n",
    "            inst['case:concept:name'] = inst[case_col_src].astype(str)\n",
    "\n",
    "        # --------- 2) build an event log of COMPLETED activities ----------\n",
    "        event_log_df = inst.rename(columns={\n",
    "            'activity': 'concept:name',\n",
    "            'end_ts': 'time:timestamp'\n",
    "        })[['case:concept:name', 'concept:name', 'time:timestamp', 'org:resource']].copy()\n",
    "\n",
    "        # timestamps are minutes-from-zero; map to datetime\n",
    "        event_log_df['time:timestamp'] = pd.to_datetime(\n",
    "            event_log_df['time:timestamp'], unit='m', origin='2024-01-01'\n",
    "        )\n",
    "        event_log_df['case:concept:name'] = event_log_df['case:concept:name'].astype(str)\n",
    "\n",
    "        # --------- 3) convert to PM4Py EventLog (fallback to DF) ----------\n",
    "        try:\n",
    "            from pm4py.objects.conversion.log import converter as xes_converter\n",
    "            self.event_log = xes_converter.apply(\n",
    "                event_log_df, variant=xes_converter.Variants.TO_EVENT_LOG\n",
    "            )\n",
    "            n_cases = len({ev['case:concept:name'] for ev in self.event_log})\n",
    "            print(f\"📊 Prepared event log: {len(self.event_log)} events, {n_cases} cases\")\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Event log conversion failed: {e}\")\n",
    "            self.event_log = event_log_df\n",
    "            print(f\"📊 Using DataFrame directly: {len(self.event_log)} events, {event_log_df['case:concept:name'].nunique()} cases\")\n",
    "\n",
    "        return self.event_log\n",
    "    def discover_dfg(self):\n",
    "        \"\"\"Discover Directly-Follows Graph (frequency-based) with starts/ends.\"\"\"\n",
    "        print(\"🔄 Discovering Directly-Follows Graph...\")\n",
    "        try:\n",
    "            # PM4Py DFG discovery (works for EventLog or pandas DF with pm4py column names)\n",
    "            from pm4py.algo.discovery.dfg import algorithm as dfg_discovery\n",
    "            from pm4py.algo.discovery.dfg.adapters.pandas import df_statistics as dfg_stats_df\n",
    "            from pm4py.statistics.start_activities.pandas import get as start_acts_df\n",
    "            from pm4py.statistics.end_activities.pandas import get as end_acts_df\n",
    "\n",
    "            if isinstance(self.event_log, pd.DataFrame):\n",
    "                # Pandas path\n",
    "                dfg = dfg_stats_df.get_dfg_graph(self.event_log, case_id_glue=\"case:concept:name\",\n",
    "                                                 activity_key=\"concept:name\", timestamp_key=\"time:timestamp\")\n",
    "                start_activities = start_acts_df.get_start_activities(self.event_log,\n",
    "                                                                      case_id_glue=\"case:concept:name\",\n",
    "                                                                      activity_key=\"concept:name\",\n",
    "                                                                      timestamp_key=\"time:timestamp\")\n",
    "                end_activities = end_acts_df.get_end_activities(self.event_log,\n",
    "                                                                case_id_glue=\"case:concept:name\",\n",
    "                                                                activity_key=\"concept:name\",\n",
    "                                                                timestamp_key=\"time:timestamp\")\n",
    "            else:\n",
    "                # EventLog path\n",
    "                dfg = dfg_discovery.apply(self.event_log)\n",
    "                from pm4py.statistics.start_activities.log import get as start_acts_log\n",
    "                from pm4py.statistics.end_activities.log import get as end_acts_log\n",
    "                start_activities = start_acts_log.get_start_activities(self.event_log)\n",
    "                end_activities = end_acts_log.get_end_activities(self.event_log)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ DFG discovery via PM4Py failed: {e}. Falling back to manual.\")\n",
    "            dfg, start_activities, end_activities = self._calculate_dfg_manually()\n",
    "\n",
    "        # Probabilities\n",
    "        total = sum(dfg.values()) if isinstance(dfg, dict) else 0\n",
    "        dfg_probabilities = {k: v / total for k, v in dfg.items()} if total > 0 else {}\n",
    "\n",
    "        activities = list(set(a for edge in dfg.keys() for a in edge)) if dfg else list(\n",
    "            set(list(start_activities.keys()) + list(end_activities.keys()))\n",
    "        )\n",
    "\n",
    "        model = {\n",
    "            \"type\": \"dfg\",\n",
    "            \"dfg\": dfg,\n",
    "            \"dfg_probabilities\": dfg_probabilities,\n",
    "            \"start_activities\": start_activities,\n",
    "            \"end_activities\": end_activities,\n",
    "            \"activities\": activities,\n",
    "        }\n",
    "        self.models[\"dfg\"] = model\n",
    "        print(f\"✅ DFG discovered: {len(dfg)} relations | \"\n",
    "              f\"starts: {len(start_activities)} | ends: {len(end_activities)}\")\n",
    "        return model\n",
    "\n",
    "\n",
    "    def _calculate_dfg_manually(self):\n",
    "        \"\"\"Manual fallback for DFG calculation\"\"\"\n",
    "        dfg = {}\n",
    "        start_activities = {}\n",
    "        end_activities = {}\n",
    "        \n",
    "        # Handle both DataFrame and EventLog\n",
    "        if isinstance(self.event_log, pd.DataFrame):\n",
    "            # DataFrame approach\n",
    "            cases = self.event_log.groupby('case:concept:name')\n",
    "            for case_id, case_events in cases:\n",
    "                case_events_sorted = case_events.sort_values('time:timestamp')\n",
    "                \n",
    "                # Record start activity\n",
    "                if len(case_events_sorted) > 0:\n",
    "                    start_act = case_events_sorted.iloc[0]['concept:name']\n",
    "                    start_activities[start_act] = start_activities.get(start_act, 0) + 1\n",
    "                \n",
    "                # Record DFG relations\n",
    "                for i in range(len(case_events_sorted) - 1):\n",
    "                    from_act = case_events_sorted.iloc[i]['concept:name']\n",
    "                    to_act = case_events_sorted.iloc[i + 1]['concept:name']\n",
    "                    dfg[(from_act, to_act)] = dfg.get((from_act, to_act), 0) + 1\n",
    "                \n",
    "                # Record end activity\n",
    "                if len(case_events_sorted) > 0:\n",
    "                    end_act = case_events_sorted.iloc[-1]['concept:name']\n",
    "                    end_activities[end_act] = end_activities.get(end_act, 0) + 1\n",
    "        else:\n",
    "            # EventLog approach\n",
    "            cases = {}\n",
    "            for event in self.event_log:\n",
    "                case_id = event['case:concept:name']\n",
    "                if case_id not in cases:\n",
    "                    cases[case_id] = []\n",
    "                cases[case_id].append(event)\n",
    "            \n",
    "            # Sort events by timestamp within each case\n",
    "            for case_id, events in cases.items():\n",
    "                events_sorted = sorted(events, key=lambda x: x['time:timestamp'])\n",
    "                \n",
    "                # Record start activity\n",
    "                if events_sorted:\n",
    "                    start_act = events_sorted[0]['concept:name']\n",
    "                    start_activities[start_act] = start_activities.get(start_act, 0) + 1\n",
    "                \n",
    "                # Record DFG relations\n",
    "                for i in range(len(events_sorted) - 1):\n",
    "                    from_act = events_sorted[i]['concept:name']\n",
    "                    to_act = events_sorted[i + 1]['concept:name']\n",
    "                    dfg[(from_act, to_act)] = dfg.get((from_act, to_act), 0) + 1\n",
    "                \n",
    "                # Record end activity\n",
    "                if events_sorted:\n",
    "                    end_act = events_sorted[-1]['concept:name']\n",
    "                    end_activities[end_act] = end_activities.get(end_act, 0) + 1\n",
    "        \n",
    "        return dfg, start_activities, end_activities\n",
    "\n",
    "    def discover_inductive_miner(self, noise_threshold=0.2):\n",
    "        \"\"\"Discover process model using Inductive Miner\"\"\"\n",
    "        print(\"🔄 Discovering process with Inductive Miner...\")\n",
    "        \n",
    "        from pm4py.algo.discovery.inductive import algorithm as inductive_miner\n",
    "        \n",
    "        try:\n",
    "            # Use IMf variant which handles noise better\n",
    "            tree = inductive_miner.apply(self.event_log, variant=inductive_miner.Variants.IMf, \n",
    "                                       parameters={'noise_threshold': noise_threshold})\n",
    "            net, initial_marking, final_marking = pm4py.convert_to_petri_net(tree)\n",
    "            \n",
    "            model = {\n",
    "                'type': 'inductive',\n",
    "                'tree': tree,\n",
    "                'petri_net': net,\n",
    "                'initial_marking': initial_marking,\n",
    "                'final_marking': final_marking\n",
    "            }\n",
    "            \n",
    "            self.models['inductive'] = model\n",
    "            print(\"✅ Inductive Miner model discovered\")\n",
    "            return model\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Inductive Miner failed: {e}\")\n",
    "            return None\n",
    "\n",
    "    def discover_heuristics_miner(self, dependency_threshold=0.5):\n",
    "        \"\"\"Discover process model using Heuristics Miner\"\"\"\n",
    "        print(\"🔄 Discovering process with Heuristics Miner...\")\n",
    "        \n",
    "        from pm4py.algo.discovery.heuristics import algorithm as heuristics_miner\n",
    "        \n",
    "        try:\n",
    "            parameters = {\n",
    "                heuristics_miner.Variants.CLASSIC.value.Parameters.DEPENDENCY_THRESH: dependency_threshold,\n",
    "                heuristics_miner.Variants.CLASSIC.value.Parameters.MIN_ACT_COUNT: 1\n",
    "            }\n",
    "            \n",
    "            heu_net = heuristics_miner.apply(self.event_log, parameters=parameters)\n",
    "            \n",
    "            model = {\n",
    "                'type': 'heuristics',\n",
    "                'heu_net': heu_net\n",
    "            }\n",
    "            \n",
    "            self.models['heuristics'] = model\n",
    "            print(\"✅ Heuristics Miner model discovered\")\n",
    "            return model\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Heuristics Miner failed: {e}\")\n",
    "            return None\n",
    "\n",
    "    def analyze_process_variants(self):\n",
    "        \"\"\"Analyze process variants in the event log\"\"\"\n",
    "        print(\"🔍 Analyzing process variants...\")\n",
    "        \n",
    "        try:\n",
    "            variants = pm4py.get_variants_as_tuples(self.event_log)\n",
    "            \n",
    "            print(f\"📋 Found {len(variants)} unique process variants\")\n",
    "            print(\"\\nTop 10 most frequent variants:\")\n",
    "            \n",
    "            for i, (variant, count) in enumerate(sorted(variants.items(), key=lambda x: x[1], reverse=True)[:10]):\n",
    "                print(f\"{i+1:2d}. Count: {count:4d} - {' → '.join(variant)}\")\n",
    "            \n",
    "            return variants\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Variant analysis failed: {e}\")\n",
    "            return {}\n",
    "\n",
    "    def analyze_process_metrics(self):\n",
    "        \"\"\"Calculate key process metrics\"\"\"\n",
    "        print(\"📊 Calculating process metrics...\")\n",
    "        \n",
    "        metrics = {}\n",
    "        \n",
    "        try:\n",
    "            # Case statistics\n",
    "            case_durations = pm4py.get_all_case_durations(self.event_log)\n",
    "            metrics['case_durations'] = {\n",
    "                'mean': np.mean(case_durations),\n",
    "                'median': np.median(case_durations),\n",
    "                'min': np.min(case_durations),\n",
    "                'max': np.max(case_durations),\n",
    "                'std': np.std(case_durations)\n",
    "            }\n",
    "            \n",
    "            # Activity frequency - handle both DataFrame and EventLog\n",
    "            if isinstance(self.event_log, pd.DataFrame):\n",
    "                activity_counts = self.event_log['concept:name'].value_counts().to_dict()\n",
    "            else:\n",
    "                activity_counts = {}\n",
    "                for event in self.event_log:\n",
    "                    activity = event['concept:name']\n",
    "                    activity_counts[activity] = activity_counts.get(activity, 0) + 1\n",
    "            metrics['activity_frequency'] = activity_counts\n",
    "            \n",
    "            # Throughput calculation\n",
    "            if isinstance(self.event_log, pd.DataFrame):\n",
    "                start_times = self.event_log.groupby('case:concept:name')['time:timestamp'].min()\n",
    "                end_times = self.event_log.groupby('case:concept:name')['time:timestamp'].max()\n",
    "                total_time = (end_times.max() - start_times.min()).total_seconds() / 3600\n",
    "                case_count = self.event_log['case:concept:name'].nunique()\n",
    "            else:\n",
    "                timestamps = [event['time:timestamp'] for event in self.event_log]\n",
    "                if timestamps:\n",
    "                    total_time = (max(timestamps) - min(timestamps)).total_seconds() / 3600\n",
    "                    case_count = len(set(event['case:concept:name'] for event in self.event_log))\n",
    "                else:\n",
    "                    total_time = 0\n",
    "                    case_count = 0\n",
    "            \n",
    "            metrics['throughput'] = case_count / total_time if total_time > 0 else 0\n",
    "            \n",
    "            print(\"\\n📈 Process Metrics:\")\n",
    "            print(f\"   Cases: {len(case_durations)}\")\n",
    "            print(f\"   Average case duration: {metrics['case_durations']['mean']:.2f} minutes\")\n",
    "            print(f\"   Throughput: {metrics['throughput']:.2f} cases/hour\")\n",
    "            print(f\"   Unique activities: {len(activity_counts)}\")\n",
    "            \n",
    "            print(\"\\n🏭 Most frequent activities:\")\n",
    "            for activity, count in sorted(activity_counts.items(), key=lambda x: x[1], reverse=True)[:5]:\n",
    "                print(f\"   {activity}: {count} occurrences\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Metrics calculation failed: {e}\")\n",
    "            metrics = {'error': str(e)}\n",
    "        \n",
    "        return metrics\n",
    "\n",
    "    def compare_discovery_methods(self):\n",
    "        \"\"\"Compare characteristics of different discovery methods\"\"\"\n",
    "        print(\"⚖️ Comparing discovery methods...\")\n",
    "        \n",
    "        comparison = {}\n",
    "        \n",
    "        # DFG characteristics\n",
    "        if 'dfg' in self.models:\n",
    "            dfg_model = self.models['dfg']\n",
    "            comparison['dfg'] = {\n",
    "                'num_activities': len(dfg_model['activities']),\n",
    "                'num_relations': len(dfg_model['dfg']),\n",
    "                'start_activities': len(dfg_model['start_activities']),\n",
    "                'end_activities': len(dfg_model['end_activities']),\n",
    "                'description': 'Directly-Follows Graph - frequency-based relations'\n",
    "            }\n",
    "        \n",
    "        # Inductive Miner characteristics\n",
    "        if 'inductive' in self.models and self.models['inductive'] is not None:\n",
    "            inductive_model = self.models['inductive']\n",
    "            net = inductive_model['petri_net']\n",
    "            comparison['inductive'] = {\n",
    "                'num_places': len(net.places),\n",
    "                'num_transitions': len(net.transitions),\n",
    "                'num_arcs': len(net.arcs),\n",
    "                'model_complexity': len(net.places) + len(net.transitions),\n",
    "                'description': 'Inductive Miner - sound process tree converted to Petri net'\n",
    "            }\n",
    "        \n",
    "        # Heuristics Miner characteristics\n",
    "        if 'heuristics' in self.models and self.models['heuristics'] is not None:\n",
    "            comparison['heuristics'] = {\n",
    "                'description': 'Heuristics Net - dependency-based with frequency thresholds'\n",
    "            }\n",
    "        \n",
    "        print(\"\\n🔬 Discovery Method Comparison:\")\n",
    "        for method, chars in comparison.items():\n",
    "            print(f\"\\n{method.upper()}:\")\n",
    "            for key, value in chars.items():\n",
    "                print(f\"  {key}: {value}\")\n",
    "        \n",
    "        return comparison\n",
    "\n",
    "    def save_discovered_models(self, output_dir=\"discovered_models\"):\n",
    "        \"\"\"Save discovered models to files\"\"\"\n",
    "        import os\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        print(f\"💾 Saving models to {output_dir}/...\")\n",
    "        \n",
    "        # Save DFG as CSV\n",
    "        if 'dfg' in self.models:\n",
    "            dfg_data = []\n",
    "            for (from_act, to_act), count in self.models['dfg']['dfg'].items():\n",
    "                dfg_data.append({\n",
    "                    'from_activity': from_act,\n",
    "                    'to_activity': to_act,\n",
    "                    'frequency': count,\n",
    "                    'probability': self.models['dfg']['dfg_probabilities'].get((from_act, to_act), 0)\n",
    "                })\n",
    "            dfg_df = pd.DataFrame(dfg_data)\n",
    "            dfg_df.to_csv(f\"{output_dir}/dfg_relations.csv\", index=False)\n",
    "            print(\"✅ Saved DFG relations to dfg_relations.csv\")\n",
    "        \n",
    "        # Save Petri net\n",
    "        if 'inductive' in self.models and self.models['inductive'] is not None:\n",
    "            try:\n",
    "                pm4py.write_pnml(self.models['inductive']['petri_net'],\n",
    "                               self.models['inductive']['initial_marking'],\n",
    "                               self.models['inductive']['final_marking'],\n",
    "                               f\"{output_dir}/inductive_model.pnml\")\n",
    "                print(\"✅ Saved Inductive Miner model to inductive_model.pnml\")\n",
    "            except Exception as e:\n",
    "                print(f\"⚠️ Failed to save Inductive Miner model: {e}\")\n",
    "        \n",
    "        # Save event log in XES format\n",
    "        try:\n",
    "            pm4py.write_xes(self.event_log, f\"{output_dir}/event_log.xes\")\n",
    "            print(\"✅ Saved event log to event_log.xes\")\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Failed to save event log: {e}\")\n",
    "\n",
    "    # ⭐⭐⭐ MAKE SURE THESE ARE PROPERLY INDENTED INSIDE THE CLASS ⭐⭐⭐\n",
    "    def save_all_visualizations(self, output_dir=\"process_visualizations\"):\n",
    "        \"\"\"Save all visualizations as image files\"\"\"\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        print(\"💾 Saving visualizations as images...\")\n",
    "        \n",
    "        try:\n",
    "            # Save DFG\n",
    "            if 'dfg' in self.models:\n",
    "                from pm4py.visualization.dfg import visualizer as dfg_visualizer\n",
    "                gviz = dfg_visualizer.apply(self.models['dfg']['dfg'], \n",
    "                                          self.models['dfg']['start_activities'],\n",
    "                                          self.models['dfg']['end_activities'])\n",
    "                dfg_visualizer.save(gviz, f\"{output_dir}/dfg.png\")\n",
    "                print(\"✅ Saved DFG as dfg.png\")\n",
    "            \n",
    "            # Save Process Tree\n",
    "            if 'inductive' in self.models and self.models['inductive'] is not None:\n",
    "                from pm4py.visualization.process_tree import visualizer as pt_visualizer\n",
    "                gviz = pt_visualizer.apply(self.models['inductive']['tree'])\n",
    "                pt_visualizer.save(gviz, f\"{output_dir}/process_tree.png\")\n",
    "                print(\"✅ Saved Process Tree as process_tree.png\")\n",
    "                \n",
    "                # Save Petri Net\n",
    "                from pm4py.visualization.petri_net import visualizer as pn_visualizer\n",
    "                gviz = pn_visualizer.apply(self.models['inductive']['petri_net'],\n",
    "                                         self.models['inductive']['initial_marking'],\n",
    "                                         self.models['inductive']['final_marking'])\n",
    "                pn_visualizer.save(gviz, f\"{output_dir}/petri_net.png\")\n",
    "                print(\"✅ Saved Petri Net as petri_net.png\")\n",
    "            \n",
    "            # Save Heuristics Net\n",
    "            if 'heuristics' in self.models and self.models['heuristics'] is not None:\n",
    "                from pm4py.visualization.heuristics_net import visualizer as hn_visualizer\n",
    "                gviz = hn_visualizer.apply(self.models['heuristics']['heu_net'])\n",
    "                hn_visualizer.save(gviz, f\"{output_dir}/heuristics_net.png\")\n",
    "                print(\"✅ Saved Heuristics Net as heuristics_net.png\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ PM4Py visualization failed: {e}\")\n",
    "            print(\"🔄 Trying alternative approach...\")\n",
    "            self._create_visualizations_directly(output_dir)\n",
    "\n",
    "    def _create_visualizations_directly(self, output_dir):\n",
    "        \"\"\"Create visualizations without relying on PM4Py's EventLog\"\"\"\n",
    "        print(\"🎨 Creating visualizations using graphviz directly...\")\n",
    "        \n",
    "        try:\n",
    "            # 1. Create DFG visualization using graphviz directly\n",
    "            if 'dfg' in self.models:\n",
    "                import graphviz\n",
    "                \n",
    "                dot = graphviz.Digraph(comment='Manufacturing Process DFG')\n",
    "                dot.attr(rankdir='LR', size='8,5')\n",
    "                \n",
    "                # Add nodes (activities)\n",
    "                for activity in self.models['dfg']['activities']:\n",
    "                    dot.node(activity, activity)\n",
    "                \n",
    "                # Add edges (DFG relations) with weights\n",
    "                for (from_act, to_act), count in self.models['dfg']['dfg'].items():\n",
    "                    # Calculate line thickness based on frequency\n",
    "                    thickness = max(1, min(5, count / 100))\n",
    "                    dot.edge(from_act, to_act, label=str(count), penwidth=str(thickness))\n",
    "                \n",
    "                dot.render(f'{output_dir}/dfg', format='png', cleanup=True)\n",
    "                print(\"✅ Saved DFG as dfg.png\")\n",
    "            \n",
    "            # 2. Create a simple process flow diagram\n",
    "            if 'dfg' in self.models:\n",
    "                import graphviz\n",
    "                \n",
    "                # Create a cleaner version showing main flow\n",
    "                dot = graphviz.Digraph(comment='Manufacturing Main Flow')\n",
    "                dot.attr(rankdir='LR', size='8,5')\n",
    "                \n",
    "                # Define the expected main flow\n",
    "                main_flow = ['MOULDING', 'ASSEMBLY_1', 'ASSEMBLY_2', 'SORTING', 'PACKAGING', 'END']\n",
    "                \n",
    "                # Add nodes in order\n",
    "                for activity in main_flow:\n",
    "                    if activity in self.models['dfg']['activities']:\n",
    "                        dot.node(activity, activity)\n",
    "                \n",
    "                # Connect main flow\n",
    "                for i in range(len(main_flow) - 1):\n",
    "                    if main_flow[i] in self.models['dfg']['activities'] and main_flow[i+1] in self.models['dfg']['activities']:\n",
    "                        count = self.models['dfg']['dfg'].get((main_flow[i], main_flow[i+1]), 0)\n",
    "                        if count > 0:\n",
    "                            dot.edge(main_flow[i], main_flow[i+1], label=f'{count}', color='blue')\n",
    "                \n",
    "                # Add rework loops in red\n",
    "                rework_activities = ['MOULDING', 'ASSEMBLY_1', 'ASSEMBLY_2', 'SORTING', 'PACKAGING']\n",
    "                for activity in rework_activities:\n",
    "                    if activity in self.models['dfg']['activities']:\n",
    "                        rework_count = self.models['dfg']['dfg'].get((activity, activity), 0)\n",
    "                        if rework_count > 0:\n",
    "                            dot.edge(activity, activity, label=f'{rework_count}', color='red', style='dashed')\n",
    "                \n",
    "                dot.render(f'{output_dir}/process_flow', format='png', cleanup=True)\n",
    "                print(\"✅ Saved Process Flow as process_flow.png\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Direct visualization also failed: {e}\")\n",
    "            print(\"📊 Creating basic text-based visualization...\")\n",
    "            self.create_fallback_visualizations(output_dir)\n",
    "\n",
    "    def create_fallback_visualizations(self, output_dir):\n",
    "        \"\"\"Create simple visualizations if PM4Py fails\"\"\"\n",
    "        # Activity frequency chart\n",
    "        activity_counts = {}\n",
    "        if isinstance(self.event_log, pd.DataFrame):\n",
    "            activity_counts = self.event_log['concept:name'].value_counts().to_dict()\n",
    "        else:\n",
    "            for event in self.event_log:\n",
    "                activity = event['concept:name']\n",
    "                activity_counts[activity] = activity_counts.get(activity, 0) + 1\n",
    "        \n",
    "        plt.figure(figsize=(12, 8))\n",
    "        activities = list(activity_counts.keys())\n",
    "        counts = list(activity_counts.values())\n",
    "        \n",
    "        plt.bar(activities, counts)\n",
    "        plt.title('Activity Frequency in Manufacturing Process')\n",
    "        plt.xlabel('Activities')\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"{output_dir}/activity_frequency.png\", dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(\"✅ Saved activity frequency chart as activity_frequency.png\")\n",
    "        \n",
    "        # Print DFG relations as text\n",
    "        if 'dfg' in self.models:\n",
    "            dfg = self.models['dfg']['dfg']\n",
    "            print(\"\\n🔗 Top Directly-Follows Relations:\")\n",
    "            for (from_act, to_act), count in sorted(dfg.items(), key=lambda x: x[1], reverse=True)[:15]:\n",
    "                print(f\"  {from_act} → {to_act}: {count} times\")\n",
    "\n",
    "    def run_complete_mining(self, run_id=0):\n",
    "        \"\"\"Run complete process mining pipeline\"\"\"\n",
    "        print(\"=\" * 70)\n",
    "        print(f\"🔨 COMPLETE PROCESS MINING - Run {run_id}\")\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "        try:\n",
    "            # 1. Prepare data\n",
    "            self.prepare_event_log(run_id=run_id)\n",
    "            \n",
    "            # 2. Discover models\n",
    "            dfg_model = self.discover_dfg()\n",
    "            inductive_model = self.discover_inductive_miner()\n",
    "            heuristics_model = self.discover_heuristics_miner()\n",
    "            \n",
    "            # 3. Analyze variants and metrics\n",
    "            variants = self.analyze_process_variants()\n",
    "            metrics = self.analyze_process_metrics()\n",
    "            \n",
    "            # 4. Compare methods\n",
    "            comparison = self.compare_discovery_methods()\n",
    "            \n",
    "            # 5. Save results\n",
    "            self.save_discovered_models()\n",
    "            \n",
    "            # 6. Save visualizations as images (guaranteed to work)\n",
    "            self.save_all_visualizations()\n",
    "            \n",
    "            print(\"\\n🎉 PROCESS MINING COMPLETE!\")\n",
    "            \n",
    "            return {\n",
    "                'models': self.models,\n",
    "                'variants': variants,\n",
    "                'metrics': metrics,\n",
    "                'comparison': comparison\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Process mining failed: {e}\")\n",
    "            import traceback\n",
    "            print(f\"🔍 Detailed traceback: {traceback.format_exc()}\")\n",
    "            return None\n",
    "\n",
    "# =============================================================================\n",
    "# MAIN EXECUTION\n",
    "# =============================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Load your data\n",
    "    df = pd.read_csv(\"results/251020FIFO_l0.28_actuator_manufacturing_with_rework.csv\")\n",
    "    \n",
    "    # Initialize miner\n",
    "    miner = ProcessMiner(df)\n",
    "    \n",
    "    # Run complete mining on a single simulation run\n",
    "    results = miner.run_complete_mining(run_id=0)\n",
    "    \n",
    "    if results:\n",
    "        print(\"\\n🎉 ALL DONE! Check these folders for results:\")\n",
    "        print(\"📁 'process_visualizations' - PNG images of process models\")\n",
    "        print(\"📁 'discovered_models' - CSV, PNML, and XES files\")\n",
    "    else:\n",
    "        print(\"\\n❌ Process mining failed. Check the error messages above.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db67b9b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Could not load \"C:\\Users\\990215322\\AppData\\Local\\miniconda3\\envs\\mupro\\Library\\bin\\gvplugin_pango.dll\" - It was found, so perhaps one of its dependents was not.  Try ldd.\n",
      "Warning: Could not load \"C:\\Users\\990215322\\AppData\\Local\\miniconda3\\envs\\mupro\\Library\\bin\\gvplugin_pango.dll\" - It was found, so perhaps one of its dependents was not.  Try ldd.\n",
      "Warning: Could not load \"C:\\Users\\990215322\\AppData\\Local\\miniconda3\\envs\\mupro\\Library\\bin\\gvplugin_pango.dll\" - It was found, so perhaps one of its dependents was not.  Try ldd.\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command '['dot.bat', '-Kdot', '-Tpng', '-O', 'test_graphviz']' returned non-zero exit status 3221225477. [stderr: b'Warning: Could not load \"C:\\\\Users\\\\990215322\\\\AppData\\\\Local\\\\miniconda3\\\\envs\\\\mupro\\\\Library\\\\bin\\\\gvplugin_pango.dll\" - It was found, so perhaps one of its dependents was not.  Try ldd.\\r\\nWarning: Could not load \"C:\\\\Users\\\\990215322\\\\AppData\\\\Local\\\\miniconda3\\\\envs\\\\mupro\\\\Library\\\\bin\\\\gvplugin_pango.dll\" - It was found, so perhaps one of its dependents was not.  Try ldd.\\r\\nWarning: Could not load \"C:\\\\Users\\\\990215322\\\\AppData\\\\Local\\\\miniconda3\\\\envs\\\\mupro\\\\Library\\\\bin\\\\gvplugin_pango.dll\" - It was found, so perhaps one of its dependents was not.  Try ldd.\\r\\n']",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m g \u001b[38;5;241m=\u001b[39m graphviz\u001b[38;5;241m.\u001b[39mDigraph()\n\u001b[0;32m      3\u001b[0m g\u001b[38;5;241m.\u001b[39medge(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mB\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m \u001b[43mg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtest_graphviz\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpng\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# should write test_graphviz.png\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\990215322\\AppData\\Local\\miniconda3\\envs\\mupro\\lib\\site-packages\\graphviz\\files.py:243\u001b[0m, in \u001b[0;36mrender\u001b[1;34m(self, filename, directory, view, cleanup, format, renderer, formatter, quiet, quiet_view)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\990215322\\AppData\\Local\\miniconda3\\envs\\mupro\\lib\\site-packages\\graphviz\\backend.py:225\u001b[0m, in \u001b[0;36mrender\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\990215322\\AppData\\Local\\miniconda3\\envs\\mupro\\lib\\site-packages\\graphviz\\backend.py:185\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(cmd, input, capture_output, check, encoding, quiet, **kwargs)\u001b[0m\n",
      "\u001b[1;31mCalledProcessError\u001b[0m: Command '['dot.bat', '-Kdot', '-Tpng', '-O', 'test_graphviz']' returned non-zero exit status 3221225477. [stderr: b'Warning: Could not load \"C:\\\\Users\\\\990215322\\\\AppData\\\\Local\\\\miniconda3\\\\envs\\\\mupro\\\\Library\\\\bin\\\\gvplugin_pango.dll\" - It was found, so perhaps one of its dependents was not.  Try ldd.\\r\\nWarning: Could not load \"C:\\\\Users\\\\990215322\\\\AppData\\\\Local\\\\miniconda3\\\\envs\\\\mupro\\\\Library\\\\bin\\\\gvplugin_pango.dll\" - It was found, so perhaps one of its dependents was not.  Try ldd.\\r\\nWarning: Could not load \"C:\\\\Users\\\\990215322\\\\AppData\\\\Local\\\\miniconda3\\\\envs\\\\mupro\\\\Library\\\\bin\\\\gvplugin_pango.dll\" - It was found, so perhaps one of its dependents was not.  Try ldd.\\r\\n']"
     ]
    }
   ],
   "source": [
    "import graphviz\n",
    "g = graphviz.Digraph()\n",
    "g.edge('A','B')\n",
    "g.render('test_graphviz', format='png')  # should write test_graphviz.png\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mupro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
